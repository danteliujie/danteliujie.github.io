<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>DanteLiujie's blog - 《Deep Learning》读书笔记</title>
    <link rel="icon" href="https://applenob.github.io/static/favicon.ico" type="image/x-icon" />
    <link rel="shortcut icon" href="https://applenob.github.io/static/favicon.ico" type="image/x-icon" />
    <meta name="description" content="">
    <meta name="author" content="Kevin Chan">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
    <script src="https://applenob.github.io/theme/html5.js"></script>
    <![endif]-->

    <!-- Le styles -->
    <link href="https://applenob.github.io/theme/bootstrap.min.css" rel="stylesheet">
    <link href="https://applenob.github.io/theme/bootstrap.min.responsive.css" rel="stylesheet">
    <link href="https://applenob.github.io/theme/local.css" rel="stylesheet">
    <link href="https://applenob.github.io/theme/pygments.css" rel="stylesheet">

    <!-- So Firefox can bookmark->"abo this site" -->
    <link href="https://applenob.github.io/feeds/all.atom.xml" rel="alternate" title="DanteLiujie's blog" type="application/atom+xml">
</head>

<body>

<div class="navbar">
    <div class="navbar-inner">
    <div class="container">

         <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
             <span class="icon-bar"></span>
             <span class="icon-bar"></span>
             <span class="icon-bar"></span>
         </a>

        <a class="brand" href="https://danteliujie.github.io">DanteLiujie's blog</a>

        <div class="nav-collapse">
        <ul class="nav">
            
        </ul>
        </div>
        
    </div>
    </div>
</div>

<div class="container">
    <div class="content">
    <div class="row">

    <div class="span9" style="width:100%">
    <div class='article'>
        <div class="content-title">
            <h1>《Deep Learning》读书笔记</h1>
            全部内容来自 <a class="url fn" href="https://applenob.github.io/author/chan.html">Kevin Chan</a> 的博客, 修改了一些显示style以获取所需的打印效果, 修正了一些小错误, 主要目的用于个人打印用.
        </div>

        <div>
		<style type="text/css">
			/*!
			*
			* IPython notebook
			*
			*/
			/* CSS font colors for translated ANSI colors. */
			.ansibold {
			  font-weight: bold;
			}
			/* use dark versions for foreground, to improve visibility */
			.ansiblack {
			  color: black;
			}
			.ansired {
			  color: darkred;
			}
			.ansigreen {
			  color: darkgreen;
			}
			.ansiyellow {
			  color: #c4a000;
			}
			.ansiblue {
			  color: darkblue;
			}
			.ansipurple {
			  color: darkviolet;
			}
			.ansicyan {
			  color: steelblue;
			}
			.ansigray {
			  color: gray;
			}
			/* and light for background, for the same reason */
			.ansibgblack {
			  background-color: black;
			}
			.ansibgred {
			  background-color: red;
			}
			.ansibggreen {
			  background-color: green;
			}
			.ansibgyellow {
			  background-color: yellow;
			}
			.ansibgblue {
			  background-color: blue;
			}
			.ansibgpurple {
			  background-color: magenta;
			}
			.ansibgcyan {
			  background-color: cyan;
			}
			.ansibggray {
			  background-color: gray;
			}
			div.cell {
			  /* Old browsers */
			  display: -webkit-box;
			  -webkit-box-orient: vertical;
			  -webkit-box-align: stretch;
			  display: -moz-box;
			  -moz-box-orient: vertical;
			  -moz-box-align: stretch;
			  display: box;
			  box-orient: vertical;
			  box-align: stretch;
			  /* Modern browsers */
			  display: flex;
			  flex-direction: column;
			  align-items: stretch;
			  border-radius: 2px;
			  box-sizing: border-box;
			  -moz-box-sizing: border-box;
			  -webkit-box-sizing: border-box;
			  border-width: 1px;
			  border-style: solid;
			  border-color: transparent;
			  width: 100%;
			  padding: 5px;
			  /* This acts as a spacer between cells, that is outside the border */
			  margin: 0px;
			  outline: none;
			  border-left-width: 1px;
			  padding-left: 5px;
			  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
			}
			div.cell.jupyter-soft-selected {
			  border-left-color: #90CAF9;
			  border-left-color: #E3F2FD;
			  border-left-width: 1px;
			  padding-left: 5px;
			  border-right-color: #E3F2FD;
			  border-right-width: 1px;
			  background: #E3F2FD;
			}
			@media print {
			  div.cell.jupyter-soft-selected {
				border-color: transparent;
			  }
			}
			div.cell.selected {
			  border-color: #ababab;
			  border-left-width: 0px;
			  padding-left: 6px;
			  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
			}
			@media print {
			  div.cell.selected {
				border-color: transparent;
			  }
			}
			div.cell.selected.jupyter-soft-selected {
			  border-left-width: 0;
			  padding-left: 6px;
			  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
			}
			.edit_mode div.cell.selected {
			  border-color: #66BB6A;
			  border-left-width: 0px;
			  padding-left: 6px;
			  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
			}
			@media print {
			  .edit_mode div.cell.selected {
				border-color: transparent;
			  }
			}
			.prompt {
			  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
			  min-width: 14ex;
			  /* This padding is tuned to match the padding on the CodeMirror editor. */
			  padding: 0.4em;
			  margin: 0px;
			  font-family: monospace;
			  text-align: right;
			  /* This has to match that of the the CodeMirror class line-height below */
			  line-height: 1.21429em;
			  /* Don't highlight prompt number selection */
			  -webkit-touch-callout: none;
			  -webkit-user-select: none;
			  -khtml-user-select: none;
			  -moz-user-select: none;
			  -ms-user-select: none;
			  user-select: none;
			  /* Use default cursor */
			  cursor: default;
			}
			@media (max-width: 540px) {
			  .prompt {
				text-align: left;
			  }
			}
			div.inner_cell {
			  min-width: 0;
			  /* Old browsers */
			  display: -webkit-box;
			  -webkit-box-orient: vertical;
			  -webkit-box-align: stretch;
			  display: -moz-box;
			  -moz-box-orient: vertical;
			  -moz-box-align: stretch;
			  display: box;
			  box-orient: vertical;
			  box-align: stretch;
			  /* Modern browsers */
			  display: flex;
			  flex-direction: column;
			  align-items: stretch;
			  /* Old browsers */
			  -webkit-box-flex: 1;
			  -moz-box-flex: 1;
			  box-flex: 1;
			  /* Modern browsers */
			  flex: 1;
			}
			/* input_area and input_prompt must match in top border and margin for alignment */
			div.input_area {
			  border: 1px solid #cfcfcf;
			  border-radius: 2px;
			  background: #f7f7f7;
			  line-height: 1.21429em;
			}
			/* This is needed so that empty prompt areas can collapse to zero height when there
			   is no content in the output_subarea and the prompt. The main purpose of this is
			   to make sure that empty JavaScript output_subareas have no height. */
			div.prompt:empty {
			  padding-top: 0;
			  padding-bottom: 0;
			}
			div.unrecognized_cell {
			  padding: 5px 5px 5px 0px;
			  /* Old browsers */
			  display: -webkit-box;
			  -webkit-box-orient: horizontal;
			  -webkit-box-align: stretch;
			  display: -moz-box;
			  -moz-box-orient: horizontal;
			  -moz-box-align: stretch;
			  display: box;
			  box-orient: horizontal;
			  box-align: stretch;
			  /* Modern browsers */
			  display: flex;
			  flex-direction: row;
			  align-items: stretch;
			}
			div.unrecognized_cell .inner_cell {
			  border-radius: 2px;
			  padding: 5px;
			  font-weight: bold;
			  color: red;
			  border: 1px solid #cfcfcf;
			  background: #eaeaea;
			}
			div.unrecognized_cell .inner_cell a {
			  color: inherit;
			  text-decoration: none;
			}
			div.unrecognized_cell .inner_cell a:hover {
			  color: inherit;
			  text-decoration: none;
			}
			@media (max-width: 540px) {
			  div.unrecognized_cell > div.prompt {
				display: none;
			  }
			}
			div.code_cell {
			  /* avoid page breaking on code cells when printing */
			}
			@media print {
			  div.code_cell {
				page-break-inside: avoid;
			  }
			}
			/* any special styling for code cells that are currently running goes here */
			div.input {
			  page-break-inside: avoid;
			  /* Old browsers */
			  display: -webkit-box;
			  -webkit-box-orient: horizontal;
			  -webkit-box-align: stretch;
			  display: -moz-box;
			  -moz-box-orient: horizontal;
			  -moz-box-align: stretch;
			  display: box;
			  box-orient: horizontal;
			  box-align: stretch;
			  /* Modern browsers */
			  display: flex;
			  flex-direction: row;
			  align-items: stretch;
			}
			@media (max-width: 540px) {
			  div.input {
				/* Old browsers */
				display: -webkit-box;
				-webkit-box-orient: vertical;
				-webkit-box-align: stretch;
				display: -moz-box;
				-moz-box-orient: vertical;
				-moz-box-align: stretch;
				display: box;
				box-orient: vertical;
				box-align: stretch;
				/* Modern browsers */
				display: flex;
				flex-direction: column;
				align-items: stretch;
			  }
			}
			/* input_area and input_prompt must match in top border and margin for alignment */
			div.input_prompt {
			  color: #303F9F;
			  border-top: 1px solid transparent;
			}
			div.input_area > div.highlight {
			  margin: 0.4em;
			  border: none;
			  padding: 0px;
			  background-color: transparent;
			}
			div.input_area > div.highlight > pre {
			  margin: 0px;
			  border: none;
			  padding: 0px;
			  background-color: transparent;
			}
			/* The following gets added to the <head> if it is detected that the user has a
			 * monospace font with inconsistent normal/bold/italic height.  See
			 * notebookmain.js.  Such fonts will have keywords vertically offset with
			 * respect to the rest of the text.  The user should select a better font.
			 * See: https://github.com/ipython/ipython/issues/1503
			 *
			 * .CodeMirror span {
			 *      vertical-align: bottom;
			 * }
			 */
			.CodeMirror {
			  line-height: 1.21429em;
			  /* Changed from 1em to our global default */
			  font-size: 14px;
			  height: auto;
			  /* Changed to auto to autogrow */
			  background: none;
			  /* Changed from white to allow our bg to show through */
			}
			.CodeMirror-scroll {
			  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
			  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
			  overflow-y: hidden;
			  overflow-x: auto;
			}
			.CodeMirror-lines {
			  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
			  /* we have set a different line-height and want this to scale with that. */
			  padding: 0.4em;
			}
			.CodeMirror-linenumber {
			  padding: 0 8px 0 4px;
			}
			.CodeMirror-gutters {
			  border-bottom-left-radius: 2px;
			  border-top-left-radius: 2px;
			}
			.CodeMirror pre {
			  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
			  /* .CodeMirror-lines */
			  padding: 0;
			  border: 0;
			  border-radius: 0;
			}
			/*

			Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
			Adapted from GitHub theme

			*/
			.highlight-base {
			  color: #000;
			}
			.highlight-variable {
			  color: #000;
			}
			.highlight-variable-2 {
			  color: #1a1a1a;
			}
			.highlight-variable-3 {
			  color: #333333;
			}
			.highlight-string {
			  color: #BA2121;
			}
			.highlight-comment {
			  color: #408080;
			  font-style: italic;
			}
			.highlight-number {
			  color: #080;
			}
			.highlight-atom {
			  color: #88F;
			}
			.highlight-keyword {
			  color: #008000;
			  font-weight: bold;
			}
			.highlight-builtin {
			  color: #008000;
			}
			.highlight-error {
			  color: #f00;
			}
			.highlight-operator {
			  color: #AA22FF;
			  font-weight: bold;
			}
			.highlight-meta {
			  color: #AA22FF;
			}
			/* previously not defined, copying from default codemirror */
			.highlight-def {
			  color: #00f;
			}
			.highlight-string-2 {
			  color: #f50;
			}
			.highlight-qualifier {
			  color: #555;
			}
			.highlight-bracket {
			  color: #997;
			}
			.highlight-tag {
			  color: #170;
			}
			.highlight-attribute {
			  color: #00c;
			}
			.highlight-header {
			  color: blue;
			}
			.highlight-quote {
			  color: #090;
			}
			.highlight-link {
			  color: #00c;
			}
			/* apply the same style to codemirror */
			.cm-s-ipython span.cm-keyword {
			  color: #008000;
			  font-weight: bold;
			}
			.cm-s-ipython span.cm-atom {
			  color: #88F;
			}
			.cm-s-ipython span.cm-number {
			  color: #080;
			}
			.cm-s-ipython span.cm-def {
			  color: #00f;
			}
			.cm-s-ipython span.cm-variable {
			  color: #000;
			}
			.cm-s-ipython span.cm-operator {
			  color: #AA22FF;
			  font-weight: bold;
			}
			.cm-s-ipython span.cm-variable-2 {
			  color: #1a1a1a;
			}
			.cm-s-ipython span.cm-variable-3 {
			  color: #333333;
			}
			.cm-s-ipython span.cm-comment {
			  color: #408080;
			  font-style: italic;
			}
			.cm-s-ipython span.cm-string {
			  color: #BA2121;
			}
			.cm-s-ipython span.cm-string-2 {
			  color: #f50;
			}
			.cm-s-ipython span.cm-meta {
			  color: #AA22FF;
			}
			.cm-s-ipython span.cm-qualifier {
			  color: #555;
			}
			.cm-s-ipython span.cm-builtin {
			  color: #008000;
			}
			.cm-s-ipython span.cm-bracket {
			  color: #997;
			}
			.cm-s-ipython span.cm-tag {
			  color: #170;
			}
			.cm-s-ipython span.cm-attribute {
			  color: #00c;
			}
			.cm-s-ipython span.cm-header {
			  color: blue;
			}
			.cm-s-ipython span.cm-quote {
			  color: #090;
			}
			.cm-s-ipython span.cm-link {
			  color: #00c;
			}
			.cm-s-ipython span.cm-error {
			  color: #f00;
			}
			.cm-s-ipython span.cm-tab {
			  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
			  background-position: right;
			  background-repeat: no-repeat;
			}
			div.output_wrapper {
			  /* this position must be relative to enable descendents to be absolute within it */
			  position: relative;
			  /* Old browsers */
			  display: -webkit-box;
			  -webkit-box-orient: vertical;
			  -webkit-box-align: stretch;
			  display: -moz-box;
			  -moz-box-orient: vertical;
			  -moz-box-align: stretch;
			  display: box;
			  box-orient: vertical;
			  box-align: stretch;
			  /* Modern browsers */
			  display: flex;
			  flex-direction: column;
			  align-items: stretch;
			  z-index: 1;
			}
			/* class for the output area when it should be height-limited */
			div.output_scroll {
			  /* ideally, this would be max-height, but FF barfs all over that */
			  height: 24em;
			  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
			  width: 100%;
			  overflow: auto;
			  border-radius: 2px;
			  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
			  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
			  display: block;
			}
			/* output div while it is collapsed */
			div.output_collapsed {
			  margin: 0px;
			  padding: 0px;
			  /* Old browsers */
			  display: -webkit-box;
			  -webkit-box-orient: vertical;
			  -webkit-box-align: stretch;
			  display: -moz-box;
			  -moz-box-orient: vertical;
			  -moz-box-align: stretch;
			  display: box;
			  box-orient: vertical;
			  box-align: stretch;
			  /* Modern browsers */
			  display: flex;
			  flex-direction: column;
			  align-items: stretch;
			}
			div.out_prompt_overlay {
			  height: 100%;
			  padding: 0px 0.4em;
			  position: absolute;
			  border-radius: 2px;
			}
			div.out_prompt_overlay:hover {
			  /* use inner shadow to get border that is computed the same on WebKit/FF */
			  -webkit-box-shadow: inset 0 0 1px #000;
			  box-shadow: inset 0 0 1px #000;
			  background: rgba(240, 240, 240, 0.5);
			}
			div.output_prompt {
			  color: #D84315;
			}
			/* This class is the outer container of all output sections. */
			div.output_area {
			  padding: 0px;
			  page-break-inside: avoid;
			  /* Old browsers */
			  display: -webkit-box;
			  -webkit-box-orient: horizontal;
			  -webkit-box-align: stretch;
			  display: -moz-box;
			  -moz-box-orient: horizontal;
			  -moz-box-align: stretch;
			  display: box;
			  box-orient: horizontal;
			  box-align: stretch;
			  /* Modern browsers */
			  display: flex;
			  flex-direction: row;
			  align-items: stretch;
			}
			div.output_area .MathJax_Display {
			  text-align: left !important;
			}
			div.output_area 
			div.output_area 
			div.output_area img,
			div.output_area svg {
			  max-width: 100%;
			  height: auto;
			}
			div.output_area img.unconfined,
			div.output_area svg.unconfined {
			  max-width: none;
			}
			/* This is needed to protect the pre formating from global settings such
			   as that of bootstrap */
			.output {
			  /* Old browsers */
			  display: -webkit-box;
			  -webkit-box-orient: vertical;
			  -webkit-box-align: stretch;
			  display: -moz-box;
			  -moz-box-orient: vertical;
			  -moz-box-align: stretch;
			  display: box;
			  box-orient: vertical;
			  box-align: stretch;
			  /* Modern browsers */
			  display: flex;
			  flex-direction: column;
			  align-items: stretch;
			}
			@media (max-width: 540px) {
			  div.output_area {
				/* Old browsers */
				display: -webkit-box;
				-webkit-box-orient: vertical;
				-webkit-box-align: stretch;
				display: -moz-box;
				-moz-box-orient: vertical;
				-moz-box-align: stretch;
				display: box;
				box-orient: vertical;
				box-align: stretch;
				/* Modern browsers */
				display: flex;
				flex-direction: column;
				align-items: stretch;
			  }
			}
			div.output_area pre {
			  margin: 0;
			  padding: 0;
			  border: 0;
			  vertical-align: baseline;
			  color: black;
			  background-color: transparent;
			  border-radius: 0;
			}
			/* This class is for the output subarea inside the output_area and after
			   the prompt div. */
			div.output_subarea {
			  overflow-x: auto;
			  padding: 0.4em;
			  /* Old browsers */
			  -webkit-box-flex: 1;
			  -moz-box-flex: 1;
			  box-flex: 1;
			  /* Modern browsers */
			  flex: 1;
			  max-width: calc(100% - 14ex);
			}
			div.output_scroll div.output_subarea {
			  overflow-x: visible;
			}
			/* The rest of the output_* classes are for special styling of the different
			   output types */
			/* all text output has this class: */
			div.output_text {
			  text-align: left;
			  color: #000;
			  /* This has to match that of the the CodeMirror class line-height below */
			  line-height: 1.21429em;
			}
			/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
			div.output_stderr {
			  background: #fdd;
			  /* very light red background for stderr */
			}
			div.output_latex {
			  text-align: left;
			}
			/* Empty output_javascript divs should have no height */
			div.output_javascript:empty {
			  padding: 0;
			}
			.js-error {
			  color: darkred;
			}
			/* raw_input styles */
			div.raw_input_container {
			  line-height: 1.21429em;
			  padding-top: 5px;
			}
			pre.raw_input_prompt {
			  /* nothing needed here. */
			}
			input.raw_input {
			  font-family: monospace;
			  font-size: inherit;
			  color: inherit;
			  width: auto;
			  /* make sure input baseline aligns with prompt */
			  vertical-align: baseline;
			  /* padding + margin = 0.5em between prompt and cursor */
			  padding: 0em 0.25em;
			  margin: 0em 0.25em;
			}
			input.raw_input:focus {
			  box-shadow: none;
			}
			p.p-space {
			  margin-bottom: 10px;
			}
			div.output_unrecognized {
			  padding: 5px;
			  font-weight: bold;
			  color: red;
			}
			div.output_unrecognized a {
			  color: inherit;
			  text-decoration: none;
			}
			div.output_unrecognized a:hover {
			  color: inherit;
			  text-decoration: none;
			}
			.rendered_html {
			  color: #000;
			  /* any extras will just be numbers: */
			}



			.rendered_html :link {
			  text-decoration: underline;
			}
			.rendered_html :visited {
			  text-decoration: underline;
			}






			.rendered_html h1:first-child {
			  margin-top: 0.538em;
			}
			.rendered_html h2:first-child {
			  margin-top: 0.636em;
			}
			.rendered_html h3:first-child {
			  margin-top: 0.777em;
			}
			.rendered_html h4:first-child {
			  margin-top: 1em;
			}
			.rendered_html h5:first-child {
			  margin-top: 1em;
			}
			.rendered_html h6:first-child {
			  margin-top: 1em;
			}








			.rendered_html * + ul {
			  margin-top: 1em;
			}
			.rendered_html * + ol {
			  margin-top: 1em;
			}


			.rendered_html pre,



			.rendered_html tr,
			.rendered_html th,

			.rendered_html td,


			.rendered_html * + table {
			  margin-top: 1em;
			}

			.rendered_html * + p {
			  margin-top: 1em;
			}

			.rendered_html * + img {
			  margin-top: 1em;
			}
			.rendered_html img,

			.rendered_html img.unconfined,

			div.text_cell {
			  /* Old browsers */
			  display: -webkit-box;
			  -webkit-box-orient: horizontal;
			  -webkit-box-align: stretch;
			  display: -moz-box;
			  -moz-box-orient: horizontal;
			  -moz-box-align: stretch;
			  display: box;
			  box-orient: horizontal;
			  box-align: stretch;
			  /* Modern browsers */
			  display: flex;
			  flex-direction: row;
			  align-items: stretch;
			}
			@media (max-width: 540px) {
			  div.text_cell > div.prompt {
				display: none;
			  }
			}
			div.text_cell_render {
			  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
			  outline: none;
			  resize: none;
			  width: inherit;
			  border-style: none;
			  padding: 0.5em 0.5em 0.5em 0.4em;
			  color: #000;
			  box-sizing: border-box;
			  -moz-box-sizing: border-box;
			  -webkit-box-sizing: border-box;
			}
			a.anchor-link:link {
			  text-decoration: none;
			  padding: 0px 20px;
			  visibility: hidden;
			}
			h1:hover .anchor-link,
			h2:hover .anchor-link,
			h3:hover .anchor-link,
			h4:hover .anchor-link,
			h5:hover .anchor-link,
			h6:hover .anchor-link {
			  visibility: visible;
			}
			.text_cell.rendered .input_area {
			  display: none;
			}
			.text_cell.rendered 
			.text_cell.unrendered .text_cell_render {
			  display: none;
			}
			.cm-header-1,
			.cm-header-2,
			.cm-header-3,
			.cm-header-4,
			.cm-header-5,
			.cm-header-6 {
			  font-weight: bold;
			  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
			}
			.cm-header-1 {
			  font-size: 185.7%;
			}
			.cm-header-2 {
			  font-size: 157.1%;
			}
			.cm-header-3 {
			  font-size: 128.6%;
			}
			.cm-header-4 {
			  font-size: 110%;
			}
			.cm-header-5 {
			  font-size: 100%;
			  font-style: italic;
			}
			.cm-header-6 {
			  font-size: 100%;
			  font-style: italic;
			}
		</style>
		<style type="text/css">
			.highlight .hll { background-color: #ffffcc }
			.highlight  { background: #f8f8f8; }
			.highlight .c { color: #408080; font-style: italic } /* Comment */
			.highlight .err { border: 1px solid #FF0000 } /* Error */
			.highlight .k { color: #008000; font-weight: bold } /* Keyword */
			.highlight .o { color: #666666 } /* Operator */
			.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
			.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
			.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
			.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
			.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
			.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
			.highlight .gd { color: #A00000 } /* Generic.Deleted */
			.highlight .ge { font-style: italic } /* Generic.Emph */
			.highlight .gr { color: #FF0000 } /* Generic.Error */
			.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
			.highlight .gi { color: #00A000 } /* Generic.Inserted */
			.highlight .go { color: #888888 } /* Generic.Output */
			.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
			.highlight .gs { font-weight: bold } /* Generic.Strong */
			.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
			.highlight .gt { color: #0044DD } /* Generic.Traceback */
			.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
			.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
			.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
			.highlight .kp { color: #008000 } /* Keyword.Pseudo */
			.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
			.highlight .kt { color: #B00040 } /* Keyword.Type */
			.highlight .m { color: #666666 } /* Literal.Number */
			.highlight .s { color: #BA2121 } /* Literal.String */
			.highlight .na { color: #7D9029 } /* Name.Attribute */
			.highlight .nb { color: #008000 } /* Name.Builtin */
			.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
			.highlight .no { color: #880000 } /* Name.Constant */
			.highlight .nd { color: #AA22FF } /* Name.Decorator */
			.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
			.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
			.highlight .nf { color: #0000FF } /* Name.Function */
			.highlight .nl { color: #A0A000 } /* Name.Label */
			.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
			.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
			.highlight .nv { color: #19177C } /* Name.Variable */
			.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
			.highlight .w { color: #bbbbbb } /* Text.Whitespace */
			.highlight .mb { color: #666666 } /* Literal.Number.Bin */
			.highlight .mf { color: #666666 } /* Literal.Number.Float */
			.highlight .mh { color: #666666 } /* Literal.Number.Hex */
			.highlight .mi { color: #666666 } /* Literal.Number.Integer */
			.highlight .mo { color: #666666 } /* Literal.Number.Oct */
			.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
			.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
			.highlight .sc { color: #BA2121 } /* Literal.String.Char */
			.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
			.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
			.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
			.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
			.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
			.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
			.highlight .sx { color: #008000 } /* Literal.String.Other */
			.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
			.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
			.highlight .ss { color: #19177C } /* Literal.String.Symbol */
			.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
			.highlight .fm { color: #0000FF } /* Name.Function.Magic */
			.highlight .vc { color: #19177C } /* Name.Variable.Class */
			.highlight .vg { color: #19177C } /* Name.Variable.Global */
			.highlight .vi { color: #19177C } /* Name.Variable.Instance */
			.highlight .vm { color: #19177C } /* Name.Variable.Magic */
			.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
		</style>
		<style type="text/css">
			/* Temporary definitions which will become obsolete with Notebook release 5.0 */
			.ansi-black-fg { color: #3E424D; }
			.ansi-black-bg { background-color: #3E424D; }
			.ansi-black-intense-fg { color: #282C36; }
			.ansi-black-intense-bg { background-color: #282C36; }
			.ansi-red-fg { color: #E75C58; }
			.ansi-red-bg { background-color: #E75C58; }
			.ansi-red-intense-fg { color: #B22B31; }
			.ansi-red-intense-bg { background-color: #B22B31; }
			.ansi-green-fg { color: #00A250; }
			.ansi-green-bg { background-color: #00A250; }
			.ansi-green-intense-fg { color: #007427; }
			.ansi-green-intense-bg { background-color: #007427; }
			.ansi-yellow-fg { color: #DDB62B; }
			.ansi-yellow-bg { background-color: #DDB62B; }
			.ansi-yellow-intense-fg { color: #B27D12; }
			.ansi-yellow-intense-bg { background-color: #B27D12; }
			.ansi-blue-fg { color: #208FFB; }
			.ansi-blue-bg { background-color: #208FFB; }
			.ansi-blue-intense-fg { color: #0065CA; }
			.ansi-blue-intense-bg { background-color: #0065CA; }
			.ansi-magenta-fg { color: #D160C4; }
			.ansi-magenta-bg { background-color: #D160C4; }
			.ansi-magenta-intense-fg { color: #A03196; }
			.ansi-magenta-intense-bg { background-color: #A03196; }
			.ansi-cyan-fg { color: #60C6C8; }
			.ansi-cyan-bg { background-color: #60C6C8; }
			.ansi-cyan-intense-fg { color: #258F8F; }
			.ansi-cyan-intense-bg { background-color: #258F8F; }
			.ansi-white-fg { color: #C5C1B4; }
			.ansi-white-bg { background-color: #C5C1B4; }
			.ansi-white-intense-fg { color: #A1A6B2; }
			.ansi-white-intense-bg { background-color: #A1A6B2; }
			.ansi-bold { font-weight: bold; }
		</style>
<div>
	<div >	
		<div >
		<h1 id="《Deep-Learning》">《Deep Learning》<a class="anchor-link" href="#《Deep-Learning》">¶</a></h1><p></p>
		<h2 id="目录">目录<a class="anchor-link" href="#目录">¶</a></h2><ul>
		<li><a href="https://danteliujie.github.io/deep_learning#0.书本介绍">0.书本介绍</a></li>
		<li><a href="https://danteliujie.github.io/deep_learning#1.-Introduction">1. Introduction</a></li>
		<li><a href="https://danteliujie.github.io/deep_learning#2.-Linear-Algebra">2. Linear Algebra</a></li>
		<li><a href="https://danteliujie.github.io/deep_learning#3.-Probability-and-Information-Theory">3. Probability and Information Theory</a></li>
		<li><a href="https://danteliujie.github.io/deep_learning#4.-Numerical-Computation">4. Numerical Computation</a></li>
		<li><a href="https://danteliujie.github.io/deep_learning#5.-Machine-Learning-Basics">5. Machine Learning Basics</a></li>
		<li><a href="https://danteliujie.github.io/deep_learning#6.-Deep-Feedforward-Networks">6. Deep Feedforward Networks</a></li>
		<li><a href="https://danteliujie.github.io/deep_learning#7.-Regularization-for-Deep-Learning">7. Regularization for Deep Learning</a></li>
		<li><a href="https://danteliujie.github.io/deep_learning#8.-Optimization-for-Training-Deep-Models">8. Optimization for Training Deep Models</a></li>
		<li><a href="https://danteliujie.github.io/deep_learning#9.-Convolutional-Networks">9. Convolutional Networks</a></li>
		<li><a href="https://danteliujie.github.io/deep_learning#10.-Sequence-Modeling:-Recurrent-and-Recursive-Nets">10. Sequence Modeling: Recurrent and Recursive Nets</a></li>
		<li><a href="https://danteliujie.github.io/deep_learning#11.-Practical-Methodology">11. Practical Methodology</a></li>
		<li><a href="https://danteliujie.github.io/deep_learning#12.-Application">12. Application</a></li>
		<li><a href="https://danteliujie.github.io/deep_learning#13.-Linear-Factor-Models">13. Linear Factor Models</a></li>
		<li><a href="https://danteliujie.github.io/deep_learning#14.-Autoencoders">14. Autoencoders</a></li>
		<li><a href="https://danteliujie.github.io/deep_learning#15.-Representation-Learning">15. Representation Learning</a></li>
		<li><a href="https://danteliujie.github.io/deep_learning#16.-Structured-Probabilistic-Models-for-Deep-Learning">16. Structured Probabilistic Models for Deep Learning</a></li>
		<li><a href="https://danteliujie.github.io/deep_learning#17.-Monte-Carlo-Methods">17. Monte Carlo Methods</a></li>
		<li><a href="https://danteliujie.github.io/deep_learning#18.-Confronting-the-Partition-Function">18. Confronting the Partition Function</a></li>
		<li><a href="https://danteliujie.github.io/deep_learning#19.-Approximate-Inference">19. Approximate Inference</a></li>
		<li><a href="https://danteliujie.github.io/deep_learning#20.-Deep-Generative-Models">20. Deep Generative Models</a></li>
		</ul>
		<hr />
		<hr />
		<h2 id="0.书本介绍">0.书本介绍<a class="anchor-link" href="#0.书本介绍">¶</a></h2><p><a href="https://book.douban.com/subject/26883982/">Deep Learning</a></p>
		<p><a href="http://www.deeplearningbook.org/">原版阅读网站</a></p>
		<p>作者:  <strong>Ian Goodfellow / Yoshua Bengio / Aaron Courville </strong></p>
		<p>内容简介：</p>
		<pre><code>"Written by three experts in the field, Deep Learning is the only comprehensive book on the subject." -- Elon Musk, co-chair of OpenAI; co-founder and CEO of Tesla and SpaceX
		Deep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning.
		The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models.
		Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors.</code></pre>
		<p>这本书由GAN的发明人Ian Goodfellow主写，系统地介绍了深度学习的基础知识和后续发展，是一本值得反复读的好书。</p>
		<p>这里我做的笔记是基于本书的框架，但内容不限于来自本书，最终目的是加深对知识本身的理解。</p>
		<p>笔记也会不断更新，只要在今后在工作中碰到其中的问题需要进一步研究学习，就会继续丰富此笔记的内容。</p>
		<hr />
		<hr />
		<h2 id="1.-Introduction">1. Introduction<a class="anchor-link" href="#1.-Introduction">¶</a></h2><p>什么是<strong>machine learning</strong>?</p>
		<p>在原始的AI系统中，定义不同的case使用不同的解决方法，这称为“hard code”。进一步的AI系统需要一种去获取知识的能力，也就是从原始数据中发现模式（“Pattern”），这种能力就是<strong>machine learning</strong>。</p>
		<p>但是，一般的machine learning算法严重依赖于数据的<strong>表示(representation)</strong>，表示中包含的每份信息又称为<strong>feature</strong>。</p>
		<p>这又引发了一个新的问题，对于很多task，我们不知道应该提取什么样的特征（只能经验主义）。</p>
		<p>于是又有了<strong>representation learning</strong>，即使用machine learning不光光是学习reprsentation到output的映射（mapping），还要学习data到representation的映射。</p>
		<p>典型的表示学习算法是<strong>autoencoder</strong>。encoder函数是将输入数据映射成表示;decoder函数将表示映射回原始数据的格式。</p>
		<p>representation learning的难点：表示是多种多样的，一种表示学习算法很难覆盖多种层次和不同类型的表示。</p>
		<p><strong>Deep Learning</strong>：使用多层次的结构，用简单的表示来获取高层的表示。这样，解决了上面的问题（一种方法）。</p>
		<p><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/dl.png" /></p>
		<hr />
		<h1 id="2.-Linear-Algebra">2. Linear Algebra<a class="anchor-link" href="#2.-Linear-Algebra">¶</a></h1><p><strong>基础概念</strong>：</p>
		<ul>
		<li>Scalars: 一个数；</li>
		<li>Vctors: 一列数；</li>
		<li>Matrices: 二位数组的数，每个元素由两个下标确定；</li>
		<li>Tensors: 多维数组的数。</li>
		</ul>
		<p><strong>转置（transpose）</strong>：$(A^T)_{i,j}=A_{j,i}$</p>
		<p><strong>矩阵乘法</strong>: $C=AB$， $C_{i,j}=\sum_kA_{i,k}B_{k,j}$</p>
		<p><strong>元素乘法(element product; Hardamard product)</strong>：$A \bigodot B$</p>
		<p><strong>点乘(dot product)</strong>: 向量<strong>x</strong>，<strong>y</strong>的点乘：  $x^Ty$</p>
		<p><strong>单位矩阵(identic matrix)</strong>: $I_n$， 斜对角的元素值是1,其他地方都是0</p>
		<p><strong>逆矩阵（inverse matrix）</strong>:</p>
		<ul>
		<li>$A^{-1}$, $A^{-1}A=I_n$</li>
		<li>方程Ax=b，如果A可逆，则$x=A^{-1}b$</li>
		</ul>
		<p><strong>线性组合（linear combination）</strong>：</p>
		<ul>
		<li>将矩阵$A$看作是不同的列向量的组合$[d1,d2,...,dn]$，每个列向量代表一个方向，$x$可以代表在每个方向上移动的距离，那么$Ax=b$可以理解成原点如何在$A$指定的各个方向上移动，最后到达$b$点。</li>
		<li>$Ax$即为线性组合，组合的对象是各个列向量，方式是$x$的元素。</li>
		</ul>
		<p><strong>生成空间（span）</strong>：对所有的$x$，生成的点$Ax$的集合，即为$A$的生成空间。</p>
		<p><strong>范数（Norm）</strong>：</p>
		<ul>
		<li>用来衡量vector的尺寸。</li>
		<li>$L^p$ norm:$||x||_p = \left ( \sum_i{|x_i|^p} \right )^{\frac{1}{p}}$</li>
		</ul>
		<p><strong>Frobenius-norm</strong>:</p>
		<ul>
		<li>用来衡量matrix的尺寸。</li>
		<li>类似于$L_2$ norm:$||A||_F=\sqrt{\sum_{i,j}{A_{i,j}^2}}$</li>
		</ul>
		<p><strong>对角阵（diagnal matrix）</strong>：除了对角线上的元素不为0,其他元素都为0。可以表示为$diag(v)$。</p>
		<p><strong>对称阵（symmetric matrix）</strong>：$A=A^T$</p>
		<p><strong>单位向量（unit vector）</strong>：$||x||_2 = 1$</p>
		<p><strong>正交（orthogonal）</strong>：如果$x^Ty=0$，则向量$x$和向量$y$彼此正交。</p>
		<p><strong>正交归一化矩阵（orthonormal matrix）</strong>：</p>
		<ul>
		<li>每行都相互正交并且都是单位向量。</li>
		<li>$A^TA=AA^T=I$，有$A^{-1}=A^T$。</li>
		</ul>
		<p><strong>特征分解</strong>：</p>
		<ul>
		<li>特征向量$v$和特征值$λ$，满足：$Av = λv$，方阵A可以这样分解：$A=Vdiag(λ)V^{-1}$，其中,$V=[v^{(1)},...,v^{(n)}]$,$λ=[λ_1, ..., λ_n]^T$。</li>
		<li>特别的，如果A是一个实对称阵，那么$A=Q∧Q^T$</li>
		</ul>
		<p><strong>正定（positive definite）</strong>：一个矩阵的所有特征值都是正的，则称这个矩阵正定。</p>
		<p><strong>奇异值分解（singular value decomposition）</strong>：</p>
		<ul>
		<li>$A = UDV^T$</li>
		<li>其中$A$是$m×n$矩阵。</li>
		<li>$U$是$m×m$正交矩阵，$U$的列向量称为左奇异向量，是$AA^T$的特征向量。</li>
		<li>$D$是$m×n$对角矩阵，对角线上的元素称为<strong>奇异值</strong>。</li>
		<li>$V$是正交$n×n$矩阵，$V$的列向量称为右奇异向量，是$A^TA$的特征向量。</li>
		</ul>
		<p><strong>伪逆（Moore-Penrose Pseudoinverse）</strong>：</p>
		<ul>
		<li>$A^+ = VD^+U^T$</li>
		<li>其中，$D^+$是由D的每个对角线元素取倒数（reciprocal）获得。</li>
		</ul>
		<p><strong>迹（Trace）</strong>：$Tr(A) = \sum_i A_{i,i} $，即<strong>对角线元素之和</strong>。</p>
		<p><strong>行列式（Determinant）</strong>：</p>
		<ul>
		<li>$det(A)$，是一个将一个matrix映射到一个实数的function。</li>
		<li>行列式的值等于矩阵的所有特征值的乘积。</li>
		</ul>
		<p><strong>奇异矩阵（singular matrix）</strong>：</p>
		<ul>
		<li>前提是方阵</li>
		

		<li>如果A(n×n)为奇异矩阵（singular matrix）&lt;=&lt; A的秩$Rank(A)&lt;n$。</li>
		<li>如果A(n×n)为非奇异矩阵（nonsingular matrix）&lt;=&给tt; A满秩，$Rank(A)=n$。</li>
		</ul>
		
		<h1 id="3.-Probability-and-Information-Theory">3. Probability and Information Theory<a class="anchor-link" href="#3.-Probability-and-Information-Theory">¶</a></h1><h2 id="概率论部分">概率论部分<a class="anchor-link" href="#概率论部分">¶</a></h2><p><strong>频率学派概率（frequentist probability）</strong>：认为概率和事件发生的频率相关。</p>
		<p><strong>贝叶斯学派概率（Bayesian probability）</strong>：认为概率是的对某件事发生的确定程度，可以理解成是确信的程度（degree of belief）。</p>
		<p><strong>随机变量（random variable）</strong>：一个可能随机获取不同值的变量。</p>
		<p><strong>概率质量函数（probability mass function，PMF）</strong>：用来描述离散随机变量的概率分布。表示为P(x)，是状态到概率的映射。</p>
		<p><strong>概率密度函数（probability density function，PDF）</strong>：用来描述连续随机变量的概率分布，p(x)。</p>
		<p><strong>条件概率（conditional probability）</strong>：$P(y=y|x=x) = \frac{P(y=y, x=x)}{P(x=x)}$</p>
		<p><strong>条件概率的链式法则（chain rule of conditional probability）</strong>：$P(x^{(1)}, ..., x^{(n)}) = P(x^{(1)})\prod^n_{i=2}P(x^{(i)}|x^{(1)}, ..., x^{(i-1)})$</p>
		<p><strong>独立（independence）</strong>：$\forall x \in x, y ∈ y, p(x=x, y=y) = p(x=x)p(y=y)$</p>
		<p><strong>条件独立（conditional independence）</strong>：$\forall x ∈ x, y ∈ y, z ∈ z,p(x=x, y=y | z=z) = p(x=x | z=z)p(y=y | z=z)$</p>
		<p><strong>期望（expectation）</strong>：</p>
		<ul>
		<li>期望针对某个函数$f(x)$，关于概率分布$P(x)$的平均值。</li>
		<li>对离散随机变量：$E_{x \sim P}[f(x)] = \sum_xP(x)f(x)$</li>
		<li>对连续随机变量：$E_{x \sim p}[f(x)] = \int P(x)f(x)dx$</li>
		<li>期望是线性的：$E_x[αf(x)+βg(x)] = αE_x[f(x)]+βE_x[f(x)]$</li>
		</ul>
		<p><strong>方差（variance）</strong>：</p>
		<ul>
		<li>用来衡量从随机变量$x$的分布函数$f(x)$中采样出来的一系列值和期望的偏差。</li>
		<li>$Var(x) = E[(f(x)-E[f(x)])^2]$，方差开平方即为标准差（standard deviation）。</li>
		</ul>
		<p><strong>协方差（covariance）</strong>：</p>
		<ul>
		<li>用于衡量两组值之间的线性相关程度。</li>
		<li>$Cov(f(x), g(y)) = E[(f(x)-E[f(x)])(g(y)-E[g(y)])]$。</li>
		<li>独立比协方差为0更强，因为独立还排除了非线性的相关。</li>
		</ul>
		<p><strong>贝努力分布（Bernoulli Distribution）</strong>：随机变量只有两种可能的分布，只有一个参数：$Φ$，即$x=1$的概率。</p>
		<p><strong>多项式分布（Multinoulli Distribution）</strong>随机变量有$k$种可能的分布，参数是一个长度为$k-1$的向量$p$。</p>
		<p><strong>高斯分布（Gaussian Distribution）</strong></p>
		<ul>
		<li>即正态分布（normal distribution）</li>
		<li>$\textit{N}(x;μ,σ^2) = \sqrt{\frac{1}{2πσ^2}}exp(-\frac{1}{2σ^2}(x-μ)^2)$。</li>
		<li>中心极限定理（central limit theorem）认为，大量的独立随机变量的和近似于一个高斯分布，这一点可以大量使用在应用中，我们可以认为噪声是属于正态分布的。</li>
		<li><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/gauss.PNG" /></li>
		</ul>
		<p><strong>多元正态分布（multivariate normal distribution）</strong>：</p>
		<ul>
		<li>给定协方差矩阵$\mathbf{Σ}$（正定对称），$\textit{N}(x;μ,Σ) = \sqrt{\frac{1}{(2π)^ndet(Σ)}}exp(-\frac{1}{2}(x-μ)^TΣ^{-1}(x-μ))$</li>
		<li><img alt="" src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/MultivariateNormal.png/450px-MultivariateNormal.png" /></li>
		</ul>
		<p><strong>指数分布（exponential distribution）</strong>：</p>
		<ul>
		<li>在深度学习的有研究中，经常会用到在x=0点获得最高的概率的分布，$p(x; λ) = λ\mathbf{1}_{x≥0}exp(-λx)$，或者：$f(x) = \left\{\begin{matrix}λexp(-λx) \;\;\;\; x≥0 \\0 \;\;\;\; else \end{matrix}\right.$，其中λ > 0是分布的一个参数，常被称为率参数（rate parameter）。</li>
		<li><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/exp_dis.png" /></li>
		</ul>
		<p><strong>拉普拉斯分布（Laplace Distribution）</strong>：</p>
		<ul>
		<li>另一个可以在一个点获得比较高的概率的分布。</li>
		<li>$Laplace(x ;μ,γ) = \frac{1}{2γ}exp(-\frac{|x-μ|}{γ})$</li>
		<li><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/laplace.jpg" /></li>
		</ul>
		<p><strong>迪拉克分布（Dirac Distribution）</strong>：</p>
		<ul>
		<li>$p(x) = δ(x-μ)$，这是一个泛函数。迪拉克分布经常被用于组成经验分布（empirical distribution）</li>
		<li>$p(x) = \frac{1}{m}\sum_{i=1}^m{δ(x-x^{(i)})}$</li>
		<li><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/dirac.png" /></li>
		</ul>
		<p><strong>逻辑斯蒂函数（logistic function）</strong>：</p>
		<ul>
		<li>$σ(x) = \frac{1}{1+exp(-x)}$，常用来生成贝努力分布的Φ参数。</li>
		<li><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/logistic.png" /></li>
		</ul>
		<p><strong>softplus function</strong>:</p>
		<ul>
		<li>$ζ(x) = log(1+exp(x))$，是“取正”函数的“soft”版</li>
		<li>$x^+ = max(0, x)$</li>
		<li><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/softplus.png" /></li>
		</ul>
		<p><strong>贝叶斯公式（Bayes' Rule）</strong>：$P(x|y) = \frac{P(x)P(y|x)}{P(y)}$</p>
		<h2 id="信息论部分">信息论部分<a class="anchor-link" href="#信息论部分">¶</a></h2><p><strong>信息论背后的直觉： 学习一件不太可能的事件比学习一件比较可能的事件更有信息量。</strong></p>
		<p><strong>信息（information）需要满足的三个条件</strong>：</p>
		<ul>
		<li>1.比较可能发生的事件的信息量要少；</li>
		<li>2.比较不可能发生的事件的信息量要大；</li>
		<li>3.独立发生的事件之间的信息量应该是可以叠加的。</li>
		</ul>
		<p><strong>自信息（Self-Information）：</strong>对事件$x=x$，$I(x) = -logP(x)$，满足上面三个条件，单位是nats（底为e）</p>
		<p><strong>香农熵（Shannon Entropy）</strong>：</p>
		<ul>
		<li>自信息只包含一个事件的信息。</li>
		<li><strong>对于整个概率分布$p(x)$</strong>，不确定性可以这样衡量：$E_{x\sim P}[I(x)] = -E_{x\sim P}[logP(x)]$。</li>
		<li>也可以表示成$H(P)$。</li>
		</ul>
		<p><strong>多个随机变量</strong>：</p>
		<p><strong>1.联合熵（Joint Entropy）</strong>：$H(X,Y)=-∑_{x,y}p(x,y)log(p(x,y))$，同时考虑多个事件的条件下（即考虑联合分布概率）的熵。</p>
		<p><strong>2.条件熵（Conditional Entropy）</strong>：$H(X|Y)=-∑_yp(y)∑_xp(x|y)log(p(x|y))$，某件事情已经发生的情况下，另外一件事情的熵。</p>
		<p><strong>3.互信息（Mutual Information）</strong>：$I(X,Y)=H(X)+H(Y)−H(X,Y)$，两个事件的信息<strong>相交</strong>的部分。</p>
		<p><strong>4.信息变差（Variation of information）</strong>：$V(X,Y)=H(X,Y)−I(X,Y)$，两个事件的信息<strong>不相交</strong>的部分。</p>
		<p><strong>KL散度（Kullback-Leibler Divergence）</strong>：</p>
		<ul>
		<li>衡量两个分布$P(x)$和$Q(x)$之间的差距。</li>
		<li>$D_{KL}(P||Q)=E_{x\sim P}[log \frac{P(x)}{Q(x)}]=E_{x\sim P}[logP(x)-logQ(x)]$，注意$D_{KL}(P||Q)≠D_{KL}(Q||P)$</li>
		</ul>
		<p><strong>交叉熵（Cross Entropy）</strong>：</p>
		<ul>
		<li>$H(P,Q)=H(P)+D_{KL}(P||Q)=-E_{x\sim P}[logQ(x)]$</li>
		<li>假设$P$是真实分布，$Q$是模型分布，那么最小化交叉熵$H(P,Q)$可以让模型分布逼近真实分布。</li>
		</ul>
		<p><strong>注</strong>：信息论部分很好的参考资料，<a href="http://colah.github.io/posts/2015-09-Visual-Information/">colah的博客</a>。</p>
		<h2 id="图模型（Structured-Probabilistic-Models）">图模型（Structured Probabilistic Models）<a class="anchor-link" href="#图模型（Structured-Probabilistic-Models）">¶</a></h2><p><strong>有向图模型（Directed Model）</strong>：</p>
		<ul>
		<li>$p(x) = \prod_i p(x_i | Pa_g(x_i))$， 其中$Pa_g(x_i)$是$x_i$的父节点。</li>
		<li><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/dg.png" /></li>
		<li>$P(a,b,c,d,e)=p(a)p(b|a)p(c|a,b)p(d|b)p(e|c)$</li>
		</ul>
		<p><strong>无向图模型（Undirected Model）</strong>：</p>
		<ul>
		<li>所有节点都彼此联通的集合称作“团”（Clique）。</li>
		<li>$p(x)=\frac{1}{Z}\prod_i{Φ^{(i)}(C^{(i)})}$，其中，Φ称作facor，每个factor和一个团（clique）相对应。</li>
		<li><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/udg.png" /></li>
		<li>$p(a,b,c,d,e) = \frac{1}{Z}Φ^{(1)}(a,b,c)Φ^{(2)}(b,d)Φ^{(3)}(c,e)$</li>
		</ul>
		<h1 id="4.-Numerical-Computation">4. Numerical Computation<a class="anchor-link" href="#4.-Numerical-Computation">¶</a></h1><p><strong>数值优化（Numerical Computation）</strong>：通常指代那些在解决数学问题时，不使用从符号表达式中直接推导出解析解，而是使用迭代更新的方式获取答案的算法。</p>
		<p><strong>上溢和下溢（overflow/underflow）</strong>：数据太小或者太大，在计算机内存中无法表示。</p>
		<p><strong>优化问题（optimization problem）</strong>：优化目标：最小化函数：损失函数（loss function）/ 错误函数（error function）通常上标*表示最优解。$x^*=argmin f(x)$</p>
		<p><strong>临界点（critical point）</strong>：$f'(x)=0$的点称为临界点，一般临界点取得极大值或者极小值，否则为鞍点（saddle point）。</p>
		<p><strong>梯度下降（gradient descent）</strong>：$x' = x-ε\triangledown _xf(x)$，其中，ε是学习率。</p>
		<p><strong>Jacobian 矩阵（Jacobian matrix）</strong>：</p>
		<ul>
		<li>如果我们有一个函数f:$\mathbb{R}^m \rightarrow \mathbb{R}^n$</li>
		<li>那么Jacobian矩阵即为：$J_{i,j} = \frac {\partial}{\partial x_j}f(x)_i$。</li>
		</ul>
		<p><strong>Hessian 矩阵（Hessian matrix）</strong>：</p>
		<ul>
		<li>$H(f)(x)_{i,j} = \frac {\partial ^2}{\partial x_i \partial x_j}f(x)$。</li>
		<li>可以知道，Hessian矩阵是对称阵。</li>
		</ul>
		<p><strong>牛顿法（Newton's method）</strong>：</p>
		<ul>
		<li>将函数用二阶的泰勒公式近似：$f(x)≈f(x^{(0)})+(x-x^{(0)})^T\triangledown_xf(x^{(0)})+\frac{1}{2}(x-x^{(0)})^TH(f)(x^{(0)})(x-x^{(0)})$，求解临界点$x^* = x^{(0)}-H(f)(x^{(0)})^{-1}\triangledown_xf(x^{(0)})$。</li>
		<li>梯度下降称为“一阶优化算法”；牛顿法称为“二阶优化算法”。</li>
		</ul>
		<h3 id="拉格朗日对偶性">拉格朗日对偶性<a class="anchor-link" href="#拉格朗日对偶性">¶</a></h3><p><strong>原始问题</strong>：</p>
		<ul>
		<li>$f(x),c_i(x),h_j(x)$是定义在$R^n$上的连续可微函数，考虑约束最优化问题：</li>
		<li>$\underset{x\in R^n}{min}f(x)\\s.t.\;\;c_i(x)\leq 0\;\;i=1,...,k\\h_j(x)=0\;\;j=1,...,l$</li>
		<li>即有$k$个不等式约束：$c_i(x)$和$l$个等式约束：$h_j(x)$。</li>
		</ul>
		<p><strong>拉格朗日函数</strong>：</p>
		<ul>
		<li>$L(x,\alpha,\beta)=f(x)+\sum_{i=1}^k\alpha_i c_i(x)+\sum_{j=1}^l\beta_jh_j(x)$</li>
		<li>$\alpha_i$和$\beta_j$，称为<strong>拉格朗日乘子</strong>，$\alpha_i\geq 0$。</li>
		</ul>
		<p><strong>拉格朗日函数的极大极小问题</strong>：</p>
		<ul>
		<li>令$\theta_P(x) = \underset{\alpha,\beta}{max}\;L(x,\alpha,\beta)$</li>
		<li>如果存在$x$违反了原始问题的约束条件，则$\theta_P(x)=\infty$，当$x$不违反原始问题的约束条件，则$\theta_P(x)=f(x)$</li>
		<li>因此：$\underset{x}{min}\theta_P(x)=\underset{x}{min}\underset{\alpha,\beta}{max}L(x,\alpha,\beta)$等价于原问题。</li>
		</ul>
		<p><strong>对偶问题</strong>：</p>
		<ul>
		<li>$\underset{\alpha,\beta}{max}\underset{x}{min}\;L(x,\alpha,\beta)$</li>
		<li>定理：如果函数$f(x)$和$c_i(x)$是凸函数，$h_j(x)$是仿射函数，则$x^*,\alpha^*,\beta^*$是同时是原始问题和对偶问题的解的必要条件是满足KKT条件。</li>
		</ul>
		<p><strong>KKT条件</strong>：</p>
		<ul>
		<li>1.拉格朗日函数对$x$，$λ$，$α$求偏导都为0：<ul>
		<li>$\triangledown_xL(x^*,\alpha^*,\beta^*)=0$</li>
		<li>$\triangledown_{\alpha}L(x^*,\alpha^*,\beta^*)=0$</li>
		<li>$\triangledown_{\beta}L(x^*,\alpha^*,\beta^*)=0$</li>
		</ul>
		</li>
		<li>2.对于不等式约束，$\alpha_i^*c_i(x^*)=0\;\;\;i=1,...,k$（对偶互补条件）。</li>
		</ul>
		<h1 id="5.-Machine-Learning-Basics">5. Machine Learning Basics<a class="anchor-link" href="#5.-Machine-Learning-Basics">¶</a></h1><p><strong>机器学习定义</strong>：一个计算机程序，如果它能做到在任务T中的性能P随着经验E可以提高，那就可以称它是关于某类任务T和性能衡量P，从经验E中学习。</p>
		<p><strong>机器学习任务（$T$）类别</strong>：分类（classification）/缺失输入数据的分类（classification with missing data）/回归（regression）/转录（transciption）/机器翻译（machine translation）/结构化输出（structured output）/异常检测（anomaly detection）/合成和采样（synthesis and smapling）/缺失值填补（imputation of missing data）/去噪（denoising）/密度估计（density estimation）</p>
		<p><strong>机器学习的性能（$P$）</strong>：$P$因为$T$的不同而不同。对于像分类/缺失输入数据的分类/转录，使用准确率（accuracy）来衡量性能；而对于密度估计，通常输出模型在一些样本上概率对数的平均值。</p>
		<p><strong>机器学习的经验（$E$）</strong>：根据经验的不同，分为监督学习和无监督学习。监督学习：学习$p(x)$；无监督学习：学习$p(y|x)$。通常来说，无监督学习通常指代从不需要人工标注数据中提取信息。</p>
		<p><strong>泛化（generalization）</strong>：在先前未观测到的输入上表现良好的能力被称为泛化。</p>
		<p><strong>欠拟合（underfitting）和过拟合（overfitting）</strong>：机器学习的性能取决于两点因素：1.使训练误差更小；2.使训练误差和测试误差的差距更小。分别对应欠拟合的改善和过拟合的改善。</p>
		<p><strong>模型的容量（capacity）</strong>：模型的容量是指其拟合各种函数的能力。</p>
		<p><strong>VC维（Vapnik-Chervonenkis dimension）</strong>：VC维用来度量二分类器的容量。假设存在$m$个不同的$x$点的训练集，分类器可以任意地标记该$m$个不同的$x$点，VC维即$m$的最大可能值。<a href="http://www.flickering.cn/machine_learning/2015/04/vc%E7%BB%B4%E7%9A%84%E6%9D%A5%E9%BE%99%E5%8E%BB%E8%84%89/">详细解释</a></p>
		<p><strong>奥卡姆剃刀（Occam's razor）</strong>：在同样能够解释已知观测现象的假设中，我们应该挑选”最简单”的那一个。</p>
		<p><strong>没有免费的午餐定理（no free lunch theorem）</strong>：所有分类算法在分类没有见过的点的时候，他们的错误率的期望是一样的。这个定理告诉我们，必须要针对特定的任务去设计机器学习算法。</p>
		<p><strong>正则化（Regularization）</strong>：正则化是指我们针对减少泛化误差而不是训练误差，在一个机器学习算法上做的任何改动。</p>
		<p><strong>超参数（Hyperparameters）</strong>：超参数的值不能通过学习算法本身学习出来。</p>
		<p><strong>验证集（Validation Sets）</strong>：验证集用来调超参数。</p>
		<h3 id="统计学的一些基本概念：估计（Estimators）/偏差（Bias）/方差（Variance）">统计学的一些基本概念：估计（Estimators）/偏差（Bias）/方差（Variance）<a class="anchor-link" href="#统计学的一些基本概念：估计（Estimators）/偏差（Bias）/方差（Variance）">¶</a></h3><p><strong>点估计（Point Estimation）</strong>：</p>
		<p>试图为某些参数提供一个“最优”的预测。</p>
		<p>将参数$θ$的点估计记为$\hat θ$，令$\{x^{(1)}, . . . , x^{(m)}\}$是$m$个独立同分布(i.i.d.)的数据点。点估计是这些数据的任意函数：$\hat θ=g(x^{(1)}, . . . , x^{(m)})$</p>
		<p><strong>估计的偏差（Bias）</strong>：</p>
		<p>估计的偏差被定义为:$bias(\hat θ_m) = E(\hat θ_m) - θ$，即，估计的期望和真实值的差。</p>
		<p>如果$bias(\hat θ_m)=0$,那么估计量$θ_m$被称为是无偏估计。</p>
		<p><strong>估计的方差（Variance）</strong>：</p>
		<p>就是一个方差$Var(\hat θ)$。</p>
		<p>$Var(X) = E[(X - \mu)^2]$，其中$μ=E[X]$。</p>
		<p><strong>均方误差（mean squared error， MSE）</strong>：</p>
		<p>$MSE = E[(\hat θ_m - θ)^2] = Bias(\hat θ_m)^2 + Var(\hat θ_m)$</p>
		<h3 id="最大似然估计（Maximum-Likelihood-Estimation,-MLE）">最大似然估计（Maximum Likelihood Estimation, MLE）<a class="anchor-link" href="#最大似然估计（Maximum-Likelihood-Estimation,-MLE）">¶</a></h3><p>参数θ的最大似然估计：$θ_{ML} = \underset{θ}{argmax}\;p_{model}(\mathbb{X};θ) = \underset{θ}{argmax}\;\prod_{i=1}^mp_{model}(x^{(i)};θ)$，其中$\mathbb{X}=\{x^{(1)}, . . . , x^{(m)}\}$。</p>
		<p>似然函数：$p_{model}(\mathbb{X};θ)$是一族由$θ$确定在相同空间上的概率分布。可以看到，<strong>这里$θ$并不是一个随机变量，而仅仅是一个参数。</strong></p>
		<p>对数形式：$θ_{ML} = \underset{θ}{argmax}\sum_{i=1}^mlogp_{model}(x^{(i)};θ)$。</p>
		<p>是一种点估计方法。</p>
		<h3 id="贝叶斯统计（Bayesian-Statistics）">贝叶斯统计（Bayesian Statistics）<a class="anchor-link" href="#贝叶斯统计（Bayesian-Statistics）">¶</a></h3><p>最大似然估计是频率学派的观点，认为参数θ是固定的，但是未知；贝叶斯统计观点认为，数据集是直接观察得到的，因此数据集不是随机的，但是<strong>参数θ是一个随机变量</strong>。</p>
		<p>在观察到数据前,我们将$θ$的已知知识表示成<strong>先验概率分布(prior probability distribution)</strong>$p(θ)$。</p>
		<p>$p(θ|x^{(1)},x^{(2)},...,x^{(m)}) = \frac{p(x^{(1)},x^{(2)},...,x^{(m)}|θ)p(θ)}{p(x^{(1)},x^{(2)},...,x^{(m)})}$</p>
		<h3 id="最大后验(Maximum-A-Posteriori,-MAP)估计">最大后验(Maximum A Posteriori, MAP)估计<a class="anchor-link" href="#最大后验(Maximum-A-Posteriori,-MAP)估计">¶</a></h3><p>$θ_{MAP}=\underset{θ}{argmax}\;p(θ∣x)=\underset{θ}{argmax}\;logp(x∣θ)+logp(θ)$</p>
		<p>我们可以认出上式右边的$logp(x|θ)$对应着标准的对数似然项，$logp(θ)$对应着先验分布。</p>
		<p>正如全贝叶斯推断,MAP 贝叶斯推断的优势是能够利用来自先验的信息,这些信息无法从训练数据中获得。该附加信息有助于减少最大后验点估计的方差，然而,这个优点的代价是增加了偏差。</p>
		<p>依然是一种点估计方法。</p>
		<p><strong>机器学习算法的常见组成部分</strong>：一个数据集（dataset）+一个损失函数（cost function）+一个优化过程（optimization procedure）+一个模型（model）</p>
		<p><strong>维数灾难（the Curse of Dimensionality）</strong>：当数据的维数很高时，很多机器学习问题变得相当困难。 这种现象被称为维数灾难。</p>
		<h3 id="流形（manifold）学习">流形（manifold）学习<a class="anchor-link" href="#流形（manifold）学习">¶</a></h3><p>流形指连接在一起的区域。 数学上，它是指一组点，且每个点都有其邻域。 给定一个任意的点，其流形局部看起来像是欧几里得空间。</p>
		<p>日常生活中，我们将地球视为二维平面，但实际上它是三维空间中的球状流形。</p>
		<p>流形学习算法通过一个假设来克服这个障碍，该假设认为$R_n$中大部分区域都是无效的输入，有意义的输入只分布在包含少量数据点的子集构成的一组流形中，而学习函数的输出中，有意义的变化都沿着流形的方向或仅发生在我们切换到另一流形时。</p>
		<p>我们认为在人工智能的一些场景中，如涉及到处理图像、声音或者文本时，流形假设至少是近似对的。</p>
		<p>关于流形学习有一个很好的<a href="http://www.cad.zju.edu.cn/reports/%C1%F7%D0%CE%D1%A7%CF%B0.pdf">中文ppt</a>，可以作为参考材料。</p>
		<h2 id="6.-Deep-Feedforward-Networks">6. Deep Feedforward Networks<a class="anchor-link" href="#6.-Deep-Feedforward-Networks">¶</a></h2><p><strong>深度前馈网络（Deep Feedforward Networks）</strong>：也被称为前馈神经网络（feedforward neural networks），或者多层感知机（multi-layer perceptrons， MLPs）是典型的深度学习模型。前馈网络的目标是去近似一个函数$f^*$。模型之所以称为前馈，是因为信息只向前流动，没有反馈的连接。</p>
		<p><strong>基于梯度的学习（Gradient Based Learning）</strong>：神经网络模型和线性模型最大的区别在于神经网络的非线性使得损失函数<strong>不再是凸函数</strong>。这意味着神经网络的训练通常使用迭代的、基于梯度的优化，仅仅使得代价函数达到一个非常小的值；而不是像用于训练线性回归模型的线性方程求解器，或者用于训练逻辑回归或SVM的<strong>凸优化算法</strong>那样保证全局收敛。 凸优化从任何一种初始参数出发都会收敛（理论上如此——在实践中也很鲁棒但可能会遇到数值问题）。 用于非凸损失函数的随机梯度下降没有这种收敛性保证，并且对参数的初始值很敏感。 对于前馈神经网络，将所有的权重值初始化为小随机数是很重要的。 偏置可以初始化为零或者小的正值。</p>
		<p><strong>输出单元：</strong></p>
		<p><strong>1.用于高斯输出分布的线性单元（Linear Output Units）</strong>：$\hat y = W^Th+b$，通常用来预测条件高斯分布：$p(y|x)=N(y;\hat y, I)$</p>
		<p><strong>2.用于Bernoulli输出分布的sigmoid单元（Sigmoid Output Units）</strong>：二分类任务，可以通过这个输出单元解决。$\hat y = σ(w^Th+b)$，其中，σ是sigmoid函数。</p>
		<p><strong>3.用于 Multinoulli输出分布的softmax单元（Softmax Output Units）</strong>：$z=W^th+b$，而$softmax(z)_i=\frac{exp(z_i)}{\sum_jexp(z_j)}$，如果说argmax函数返回的是一个onehot的向量，那么softmax可以理解成soft版的argmax函数。</p>
		<p><strong>隐藏单元：</strong></p>
		<p><strong>1.修正线性单元（Rectified Linear Units，ReLU）</strong>：使用激活函数$g(z)=max\{0,z\}$，有$h=g(W^Tx+b)$。通常b的初始值选一个小正值，如0.1。这样relu起初很可能是被激活的。relu的一个缺点是它不能在激活值是0的时候，进行基于梯度的学习。因此又产生了各种变体。</p>
		<p><strong>1.1.maxout单元：整流线性单元的一种扩展</strong>：$g(z)_i=\underset {j∈\mathbb{G}(i)}{max}z_j$，其中，$\mathbb{G}(i)$是第i组的输入索引集$\{(i−1)k+1,…,ik\}$。</p>
		<p><strong>2.logistic sigmoid与双曲正切函数（Hyperbolic Tangent）单元</strong>：使用logistic sigmoid：$g(z)=σ(z)$；使用双曲正弦函数：$g(z)=tanh(z)$，其中, $tanh(z)=2σ(2z)-1$。 但是，在这两个函数的两端都很容易饱和，所以不鼓励用在隐藏单元中，一定要用可以优先选择双曲正弦函数。</p>
		<p><strong>通用近似性质（Universal Approximation Properties）</strong>：一个前馈神经网络如果具有线性输出层和至少一层具有激活函数（例如logistic sigmoid激活函数）的隐藏层，只要给予网络足够数量的隐藏单元，它可以以任意的精度来近似任何从一个有限维空间到另一个有限维空间的Borel可测函数。 虽然具有单层的前馈网络足以表示任何函数，但是网络层可能大得不可实现，并且可能无法正确地学习和泛化。 在很多情况下，使用更深的模型能够减少表示期望函数所需的单元的数量，并且可以减少泛化误差。</p>
		<p><strong>MLP的深度（Depth）</strong>：具有d个输入、深度为l、每个隐藏层具有n个单元的深度整流网络可以描述的线性区域的数量是$O(\begin{pmatrix}
		n\\
		d
		\end{pmatrix}^{d(l−1)}n^d)$,意味着，这是深度l的指数级。</p>
		<p><strong>后向传播算法（Back-Propagation）</strong>：后向传播算法将偏差（cost）在网络中从后往前传播，用来计算关于cost的梯度。后向传播算法本身不是学习算法，而是学习算法，像SGD，使用后向传播算法来计算梯度。对于bp的生动理解，可以参考<a href="https://zhihu.com/question/27239198/answer/89853077">知乎的这个回答</a>，“同样是利用链式法则，BP算法则机智地避开了这种冗余，它对于每一个路径只访问一次就能求顶点对所有下层节点的偏导值”；“BP算法就是主动还款。e把所欠之钱还给c，d。c，d收到钱，乐呵地把钱转发给了a，b，皆大欢喜”。
		<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/fp.png" />
		<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/bp.png" /></p>
		<p><strong>计算图（Computational Graphs）</strong>：节点代表变量（variable）；引入操作（operation）的概念，操作是一个或者多个变量的函数，如果一个变量y是由一个对于变量x的操作得来的，那么就可以画一条有向边，从x指向y；</p>
		<p><strong>微积分中的链式法则（Chain Rule）</strong>：假设y=g(x)，z=f(g(x))=f(y)，那么有$\frac{dz}{dx}=\frac{dz}{dy}\frac{dy}{dx}$；进一步，如果$x∈R^m，y∈R^n，g：R^m \rightarrow R^n，f：R^n \rightarrow R$，有$\frac{\partial z}{\partial x_i}=\sum_j \frac{\partial z}{\partial y_j}\frac{\partial y_j}{\partial x_i}$，可以写成向量形式：$\triangledown _xz(\frac{\partial y}{\partial x})^T\triangledown _yz$，其中，$\frac{\partial y}{\partial x}$是n×m的g的Jacobian矩阵。</p>
		<p><strong>不同框架的bp实现</strong>：1."symbol-to-number"：以计算图和数值作为图的输入，返回一系列<strong>微分的数值</strong>，作为输入的梯度。比如<strong>Torch</strong>，<strong>Caffe</strong>。2."symbol-to-symbol"：以计算图作为输入，开辟额外的图，来保存<strong>微分计算的符号表示</strong>。这种方法可以在学习算法中多次使用，并且可以用来计算更高阶的微分。比如<strong>Tensorflow</strong>，<strong>Theano</strong>。</p>
		<h2 id="7.-Regularization-for-Deep-Learning">7. Regularization for Deep Learning<a class="anchor-link" href="#7.-Regularization-for-Deep-Learning">¶</a></h2><p><strong>正则化（Regularization）</strong>：对学习算法的修改——旨在减少泛化误差而不是训练误差。</p>
		<p><strong>参数范数惩罚（Parameter Norm Penalties）</strong>：通过对目标函数J添加一个<strong>参数范数惩罚Ω(θ)</strong>，来限制模型的学习能力。 我们将正则化后的目标函数记为$\tilde{J}$：$\tilde{J}(θ;X,y)=J(θ;X,y)+αΩ(θ)$，其中α∈[0,∞)是权衡范数惩罚项Ω和标准目标函数 J(X;θ)相对贡献的超参数。说明，在神经网络中我们通常只对每一层仿射变换的<strong>权重w</strong>做惩罚而不对偏置做正则惩罚。典型的参数范数惩罚有$L^2$参数正则和$L^1$参数正则。</p>
		<p><strong>$L^2$参数正则（$L^2$ Parameter Regularization）</strong>：也就是<strong>权重衰减（weight decay）</strong>，顾名思义，权重会有所减小；罚项为$Ω(θ)=\frac{1}{2}||w||_2^2$，也称为<strong>岭回归（ridge regression）</strong>或Tikhonov正则。 在训练过程中，只有在显著减小目标函数方向上的参数会保留得相对完好；在无助于目标函数减小的方向（对应Hessian矩阵较小的特征值）上改变参数不会显著增加梯度。 这种不重要方向对应的分量会在训练过程中因正则化而衰减掉。</p>
		<p><strong>$L^1$参数正则（$L^1$ Parameter Regularization）</strong>：罚项为$Ω(θ)=||w||_1=\sum_i|w_i|$，相比于$L^2$正则，$L^1$正则产生更多的<strong>稀疏性结果</strong>，此处稀疏性指的是最优值中的一些参数为0。这一性质也使得$L^1$正则在<strong>特征选择</strong>机制中被广泛使用。</p>
		<p><strong>作为约束的范数惩罚</strong>：我们可以把参数范数惩罚看作对权重强加的约束。 如果Ω是$L^2$范数，那么权重就是被约束在一个$L^2$球中。 如果Ω是$L^1$范数，那么权重就是被约束在一个$L^1$范数限制的区域中。</p>
		<p><strong>数据集增强（Dataset Augmentation）</strong>：实际上，让机器学习模型泛化得更好的最好办法是使用更多的数据进行训练。 但在实践中，我们拥有的数据量是很有限的。 解决这个问题的一种方法是创建假数据并添加到训练集中。这种方法用在分类任务来说是很简单的； 但这种方法对于其他许多任务来说并不那么容易，比如密度估计问题。 数据集增强在目标识别（objective recognition）和语音识别（speech recognition）上被证实比较有效。通常情况下，人工设计的数据集增强方案可以大大减少机器学习技术的泛化误差。</p>
		<p><strong>噪声鲁棒性（Noise Robustness）</strong>：噪声可以直接注入到输入数据，作为数据集增强，向输入添加方差极小的噪声等价于对权重施加范数惩罚；也可以向隐藏单元添加噪声，这种罚项更加强大；可以直接向权重w注入噪声，经常用于rnn，它推动模型进入对权重小的变化相对不敏感的区域，找到的点不只是极小点，还是由平坦区域所包围的最小点；还可以向输出目标注入噪声，比如label smoothing。</p>
		<p><strong>半监督学习（Semi-Supervised Learning）</strong>：在深度学习的背景下，半监督学习通常指的是学习一个表示：h=f(x)。 学习表示的目的是使相同类中的样本有类似的表示。</p>
		<p><strong>多任务学习（Multi-Task Learning）</strong>：通过合并几个任务中的样例（可以视为对参数施加的软约束）来提高泛化的一种方式。 当模型的一部分在任务之间共享时，模型的这一部分更多地被约束为良好的值（假设共享是合理的），往往能更好地泛化。从深度学习的观点看，底层的先验知识如下：能解释数据变化的因素中，某些因素是跨两个或更多任务共享的。
		<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/multi-task.png" /></p>
		<p><strong>提前停止（Early Stopping）</strong>：我们经常观察到，训练误差会随着时间的推移逐渐降低，但验证集的误差会再次上升。这意味着，如果在验证集误差开始上升的时候提前停止训练，这就是“提前终止”策略。可以获得更好的模型 可能是深度学习中最常用的正则化形式。 它的流行主要是因为有效性和简单性，还可以减少训练过程的计算成本。</p>
		<p><strong>参数绑定（Parameter Tying）</strong>：A模型和已经有参数的模型B任务相似，可以让A尽可能接近B，设置罚项：$Ω(w^{(A)},w^{(B)})=‖w^{(A)}−w^{(B)}‖^2_2 $</p>
		<p><strong>参数共享（Parameter Sharing）</strong>：直接让A模型的参数等于B模型的参数，典型的应用是CNN。</p>
		<p><strong>稀疏表示（Sparse Representation）</strong>：惩罚神经网络中的激活单元，稀疏化激活单元，惩罚项：Ω(h)。稀疏表示和$L^1$正则带来的稀疏参数容易混淆，区别：稀疏表示：<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/sparse-rep.png" />稀疏参数：<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/sparse-weight.png" /></p>
		<p><strong>Bagging（Bootstrap Aggregating）</strong>：通过结合多个模型来降低泛化误差。这种方法通常又被称为“集成方法”（Ensemble Method）。具体来说，Bagging涉及构造k个不同的数据集，再训练k个模型，集合所有模型的预测结果投票得出最后结果。模型平均是一个减少泛化误差的非常强大可靠的方法。 但在作为科学论文算法的基准时，它通常是不鼓励使用的，因为任何机器学习算法都可以从模型平均中大幅获益</p>
		<p><strong>Dropout</strong>：Dropout可以被认为是集成大量深层神经网络的实用Bagging方法。 但是Dropout训练与Bagging训练不太一样。 在Bagging的情况下，所有模型都是独立的。 在Dropout的情况下，所有模型共享参数。 Dropout不仅仅是训练一个Bagging的集成模型， 并且是共享隐藏单元的集成模型。 这意味着无论其他隐藏单元是否在模型中，每个隐藏单元必须都能够表现良好。 隐藏单元必须准备好进行模型之间的交换和互换。 因此Dropout正则化每个隐藏单元不仅是一个很好的特征，更要在许多情况下是良好的特征。 除此之外，计算方便是Dropout的一个优点，Dropout的另一个显著优点是不怎么限制适用的模型或训练过程。 然而，当只有极少的训练样本可用时，Dropout不会很有效。</p>
		<p><strong>对抗训练（Adversarial Training）</strong>： 对抗训练通过鼓励网络在训练数据附近的局部区域恒定来限制这一高度敏感的局部线性行为。 这可以被看作是一种明确地向监督神经网络引入局部恒定先验的方法。</p>
		<h2 id="8.-Optimization-for-Training-Deep-Models">8. Optimization for Training Deep Models<a class="anchor-link" href="#8.-Optimization-for-Training-Deep-Models">¶</a></h2><p><strong>机器学习和纯优化问题的区别</strong>：机器学习关注某些性能度量P，定义于测试集上并且可能是不可解的，只能间接地优化P。因此通过降低代价函数J(θ)来提高P。 这一点与纯优化不同，纯优化最小化目标J本身。</p>
		<p><strong>批量（batch）梯度算法</strong>：使用整个训练集的优化算法被称为批量（batch）或确定性（deterministic）梯度算法。</p>
		<p><strong>在线（online）算法</strong>：每次只使用单个样本的优化算法有时被称为随机（stochastic）或者在线（online）算法。</p>
		<p><strong>mini batch</strong>：介于以上两者之间，使用一个以上，而又不是全部的训练样本。影响mini batch size的因素：1.更大的批量会计算更精确的梯度估计，但是回报却是小于线性的。2.极小批量通常难以充分利用多核架构。 这促使我们使用一些绝对最小批量，低于这个值的小批量处理不会减少计算时间。3.在某些硬件上使用特定大小的数组时，运行时间会更少。 尤其是在使用GPU时，通常使用2的幂数作为批量大小可以获得更少的运行时间。</p>
		<p><strong>局部极小值（local minima）的问题</strong>：如果一个足够大的训练集可以唯一确定一组模型参数，那么该模型被称为可辨认的（identifiable）；而神经网络模型是不可辨认的（最直观的原因就是权重空间对称性，weight space symmetry），这意味着神经网络代价函数具有非常多的局部极小值。 对于足够大的神经网络而言， 大部分局部极小值都具有很小的代价函数，我们能不能找到真正的全局最小点并不重要，而是需要在参数空间中找到一个代价很小（但不是最小）的点。</p>
		<p><strong>鞍点（Saddle）的问题</strong>：对于很多高维非凸函数而言，局部极小值事实上远少于另一类梯度为零的点：鞍点。在鞍点处，Hessian矩阵同时具有正负特征值。鞍点激增对训练算法的影响：对于只使用梯度信息的一阶优化算法而言，目前情况还不清楚。 鞍点附近的梯度通常会非常小。 另一方面，实验中梯度下降似乎可以在许多情况下逃离鞍点。对于牛顿法而言，鞍点显然是一个问题。 梯度下降旨在朝”下坡”移动，而非明确寻求临界点。 而牛顿法的目标是寻求梯度为零的点。 高维空间中鞍点的激增或许解释了在神经网络训练中为什么二阶方法无法成功取代梯度下降。</p>
		<p><strong>悬崖（cliffs）和梯度爆炸（exploding gradients）</strong>：多层神经网络通常存在像悬崖一样的斜率较大区域，这是由于几个较大的权重相乘导致的，在RNN中比较常见。 遇到斜率极大的悬崖结构时，梯度更新会很大程度地改变参数值，通常会完全跳过这类悬崖结构。 启发式梯度截断会干涉来减小步长，从而使其不太可能走出梯度近似为最陡下降方向的悬崖区域。
		<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/cliff.png" /></p>
		<p><strong>各种优化算法</strong>：</p>
		<p><strong>随机梯度下降（Stochastic Gradient Descent）算法</strong>：计算mini-batch中m个样本对应的梯度，取其平均值来更新参数。关键的超参是学习率ϵ。
		<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/8-1.png" /></p>
		<p><strong>动量（Momentum）算法</strong>：动量方法旨在加速学习，特别是处理高曲率、小但一致的梯度，或是带噪声的梯度。 动量算法使用变量v（velocity，速度）<strong>积累之前梯度指数级衰减的移动平均</strong>，并且继续沿该方向移动。动量=mv，当m=1时动量即v。如果动量算法总是观测到梯度g，那么它会在方向−g上不停加速，直到达到最终速度，其中步长大小为$\frac{ϵ‖g‖}{1−α}$。因此将动量的超参数视为$\frac{1}{1−α}$有助于理解。 例如，α=0.9对应着最大速度10倍于梯度下降算法。
		<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/8-2.png" /></p>
		<p><strong>Nesterov 动量算法</strong>：Nesterov 动量算法和普通的动量算法的区别在于梯度计算的位置。
		<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/8-3.png" /></p>
		<p><strong>参数初始化策略</strong>：现代的初始化策略是简单的、启发式的。也许完全确知的唯一特性是初始参数需要在不同单元间”破坏对称性”。更大的初始权重具有更强的破坏对称性的作用，有助于避免冗余的单元。有些启发式方法可用于选择权重的初始大小。 一种初始化m个输入和n输出的全连接层的权重的启发式方法是从分布$U(−\frac{1}{\sqrt{m}},\frac{1}{\sqrt{m}})$中采样权重，另一种使用标准初始化,$W_{i,j}\sim U(−\frac{6}{\sqrt{m+n}},\frac{6}{\sqrt{m+n}})$</p>
		<p><strong>自适应学习率的优化算法</strong>：</p>
		<p><strong>AdaGrad</strong>：反比于其所有梯度历史平方值总和的平方根来缩放每个参数。 累积参数梯度越大学习率下降越快。AdaGrad在某些深度学习模型上效果不错，但不是全部。
		<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/8-4.png" /></p>
		<p><strong>RMSProp</strong>：修改AdaGrad以在非凸设定下效果更好，改变梯度积累为指数加权的移动平均。RMSProp使用指数衰减平均以丢弃遥远过去的历史，使其能够在找到凸碗状结构后快速收敛， 它就像一个初始化于该碗状结构的AdaGrad算法实例。
		<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/8-5.png" />
		<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/8-6.png" /></p>
		<p><strong>Adam</strong>：“Adam”这个名字派生自”adaptive moments”。它结合了RMSProp和动量算法。
		<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/8-7.png" /></p>
		<p><strong>二阶近似方法</strong>：</p>
		<p><strong>牛顿法（Newton's Method）</strong>：牛顿法的主要制约在于计算量巨大，每一次更新参数的迭代都需要计算$H^{-1}$，假如有k个参数，那么复杂度就是$O(k^3)$。
		<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/8-8.png" /></p>
		<p><strong>共轭法（Conjugate Gradients）</strong>：共轭梯度是一种通过迭代下降的共轭方向以有效避免Hessian矩阵求逆计算的方法。在共轭梯度法中，我们寻求一个和先前线性搜索方向共轭的搜索方向。 在训练迭代t时，下一步的搜索方向$d_t$的形式如下：$d_t=∇_θJ(θ)+β_td_{t−1}$，其中，系数$βt$的大小控制我们应沿方向$d_{t−1}$加回多少到当前搜索方向上。所谓共轭，即两个方向$dt$和$d_{t−1}$，满足二次方程$d^⊤_tHd_{t−1}=0$。 对于二次曲面而言，共轭方向确保梯度沿着前一方向大小不变。
		<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/8-9.png" /></p>
		<p><strong>BFGS（Broyden-Fletcher-Goldfarb-Shanno）算法</strong>：BFGS等拟牛顿法所采用的方法是使用矩阵$M_t$近似逆，迭代地低秩更新精度以更好地近似$H^{−1}$。$ρ_t=M_tg_t$，更新步骤：$θ_{t+1}=θ_t+ϵ^*ρ_t$。</p>
		<p><strong>批标准化（Batch Normalization）</strong>：它并不是一个优化算法，而是一个自适应的重参数化的方法，试图解决训练非常深的模型的困难。批标准化提出了一种几乎可以重参数化所有深度网络的优雅方法。 重参数化显著减少了多层之间协调更新的问题。 批标准化可应用于网络的任何输入层或隐藏层。$H'=\frac{H−μ}{σ}$，其中，$μ=\frac{1}{m}∑_iH_{i,:}$，$σ=\sqrt{δ+\frac{1}{m}∑_i(H−μ)^2_i}$</p>
		<p><strong>坐标下降（Coordinate Descent）</strong>：如果我们相对于某个单一变量$x_i$最小化f(x)，然后相对于另一个变量$x_j$等等，反复循环所有的变量，我们会保证到达（局部）极小值。 这种做法被称为坐标下降，因为我们一次优化一个坐标。 当一个变量的值很大程度地影响另一个变量的最优值时，坐标下降不是一个很好的方法。</p>
		<p><strong>Polyak平均</strong>：Polyak平均会平均优化算法在参数空间访问轨迹中的几个点。当应用Polyak平均于非凸问题时，通常会使用指数衰减计算平均值：
		$θ^{(t)}=αθ^{(t−1)}+(1−α)θ^{(t)}$</p>
		<p><strong>监督预训练（Supervised Pretraning）</strong>：有时，如果模型太复杂难以优化，或是如果任务非常困难，直接训练模型来解决特定任务的挑战可能太大。 因此可以训练一个较简单的模型来求解问题，然后使模型更复杂会更有效。 训练模型来求解一个简化的问题，然后转移到最后的问题，有时也会更有效些。 这些在直接训练目标模型求解目标问题之前，训练简单模型求解简化问题的方法统称为预训练。</p>
		<p><strong>设计有助于优化的模型</strong>：改进优化的最好方法并不总是改进优化算法。 相反，深度模型中优化的许多改进来自于设计易于优化的模型。</p>
		<h1 id="9.-Convolutional-Networks">9. Convolutional Networks<a class="anchor-link" href="#9.-Convolutional-Networks">¶</a></h1><p><strong>卷积网络（Convolutional Networks）</strong>：卷积网络是指那些至少在网络的一层中使用卷积运算来替代一般的矩阵乘法运算的神经网络。</p>
		<p><strong>卷积（Convolution）操作</strong>：</p>
		<ul>
		<li>卷积是一种特殊的线性运算。 </li>
		<li>假设我们正在用激光传感器追踪一艘宇宙飞船的位置，$x(t)$表示宇宙飞船在时刻t的位置，$x$和$t$都是实值。 </li>
		<li>假设我们的传感器受到一定程度的噪声干扰。 为了得到飞船位置的低噪声估计，我们对得到的测量结果进行平均。 </li>
		<li>显然，时间上越近的测量结果越相关，所以我们采用一种加权平均的方法，对于最近的测量结果赋予更高的权重。 采用一个加权函数$w(a)$来实现，其中a表示某个测量的测量时刻：$s(t)=∫x(a)w(t−a)da$，或者用离散的表达式：$s(t)=(x∗w)(t)=∑_{a=−∞}^∞x(a)w(t−a)$。</li>
		<li>这就是卷积操作，可以用星号表示：$s(t)=(x∗w)(t)$。 </li>
		<li>$x$是输入（input）；$w$是核（kernel）；输出的$s$是特征映射（feature map）。</li>
		</ul>
		<p><strong>互相关函数（cross-correlation）</strong>：</p>
		<ul>
		<li>卷积操作在kernel中的变量是$t-a$，这保证了卷积操作是可交换的（commutative）。 </li>
		<li>许多神经网络库会实现一个相关的函数，称为互相关函数，和卷积运算几乎一样但是并没有对核进行翻转：$s(t)=∫x(a)w(a)da$。</li>
		<li><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/conv.png" /></li>
		</ul>
		<p><strong>卷积运算改进机器学习系统的动机</strong>：</p>
		<p><strong>1.稀疏交互（Sparse Interaction）</strong>：</p>
		<ul>
		<li>传统的神经网络使用矩阵乘法来建立输入与输出的连接关系，每一个输出单元与每一个输入单元都产生交互。</li>
		<li>卷积网络具有稀疏交互（也叫做稀疏连接或者稀疏权重）的特征，这是使核的大小远小于输入的大小来达到的。 </li>
		<li>如果有$m$个输入和$n$个输出，那么矩阵乘法需要m×n个参数并且相应算法的时间复杂度为$O(m×n)$。</li>
		<li>如果我们限制每一个输出拥有的连接数为k，那么稀疏的连接方法只需要$k×n$个参数以及$O(k×n)$的运行时间。 </li>
		<li>在很多实际应用中，只需保持$k$比$m$小几个数量级，就能在机器学习的任务中取得好的表现。</li>
		<li><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/sparse.png" /></li>
		</ul>
		<p><strong>2.参数共享（Parameter Sharing）</strong>：</p>
		<ul>
		<li>参数共享是指在一个模型的多个函数中使用相同的参数。 </li>
		<li>在卷积神经网络中，核的每一个元素都作用在输入的每一位置上。 </li>
		<li>卷积在存储需求和统计效率方面极大地优于稠密矩阵的乘法运算。</li>
		</ul>
		<p><strong>3.等变表示（Equivariant Representation）</strong>：</p>
		<ul>
		<li>参数共享的特殊形式使得神经网络层具有对平移等变的性质。 </li>
		<li>函数$f(x)$与$g(x)$满足$f(g(x))=g(f(x))$，就说$f(x)$对于变换$g$具有等变性(equivariant)。 </li>
		</ul>
		<p><strong>池化（pooling）</strong>：</p>
		<ul>
		<li>池化函数使用某一位置的相邻输出的总体统计特征来代替网络在该位置的输出。 </li>
		<li>例如，<strong>最大池化函数（max pooling）</strong>给出相邻矩形区域内的最大值。 </li>
		<li>其他常用的池化函数包括相邻矩形区域内的平均值、L2范数以及基于据中心像素距离的加权平均函数。 </li>
		<li>不管采用什么样的池化函数，当输入作出少量平移时，池化能够帮助输入的表示近似不变。 </li>
		<li>对于平移的不变性是指当我们对输入进行少量平移时，经过池化函数后的大多数输出并不会发生改变。 </li>
		<li><strong>局部平移不变性</strong>是一个很有用的性质，<strong>尤其是当我们关心某个特征_是否出现_而不关心它出现的具体位置时</strong>。</li>
		</ul>
		<p><strong>卷积与池化作为一种无限强的先验</strong>：</p>
		<ul>
		<li>先验的强或者弱取决于先验中概率密度的集中程度：弱先验具有较高的熵值，例如方差很大的高斯分，这样的先验允许数据对于参数的改变具有或多或少的自由性。</li>
		<li>强先验具有较低的熵值，例如方差很小的高斯分布，这样的先验在决定参数最终取值时起着更加积极的作用。 </li>
		<li>一个无限强的先验需要对一些参数的概率置零并且完全禁止对这些参数赋值，无论数据对于这些参数的值给出了多大的支持。 </li>
		<li>因此，我们可以把卷积的使用当作是对网络中一层的参数引入了一个无限强的先验概率分布。 </li>
		<li>这样做带来的一个关键的洞察是卷积和池化可能导致<strong>欠拟合</strong>；另一个关键洞察是当我们比较卷积模型的统计学习表现时，只能与其他卷积模型做比较。</li>
		</ul>
		<p><strong>深度学习框架下的卷积</strong>：</p>
		<ul>
		<li>1.通常指由多个并行卷积组成的运算，可以在多个位置提取多种类型的特征。 </li>
		<li>2.输入通常也不仅仅是实值的网格，而是由一系列向量的网格，$Z_{i,j,k}=∑_{l,m,n}V_{l,j+m−1,k+n−1}K_{i,l,m,n}$。 </li>
		<li>3.使用stride，跳过核中的一些位置来降低计算的开销，$Z_{i,j,k}=∑_{l,m,n}[V_{l,(j-1)×s+m,(k-1)×s+n}K_{i,l,m,n}]$。 </li>
		<li>4.对输入用零进行填充（zero-padding）使得它加宽。 </li>
		<li>其中，valid convolution代表不使用padding，输入尺寸是$m$，输出为$m-k+1$；same convolution代表增加padding使得输出尺寸和输入相同都为$m$；full convolution代表增加padding，使得输出尺寸为$m+k-1$。 </li>
		</ul>
		<p><strong>其他卷积函数变体</strong>：</p>
		<ul>
		<li><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/other-conv.png" /></li>
		<li><strong>局部连接网络层（locally connected layers）</strong>：$Z_{i,j,k}=∑_{l,m,n}[V_{l,j+m−1,k+n−1}w_{i,j,k,l,m,n}]$。</li>
		<li><strong>平铺卷积（tiled convolution）</strong>：平铺卷积对卷积层和局部连接层进行了折衷。$Z_{i,j,k}=∑_{l,m,n}V_{l,j+m−1,k+n−1}K_{i,l,m,n,j\%  t+1,k\%t+1}$</li>
		</ul>
		<p><strong>卷积网络的训练</strong>：</p>
		<ul>
		<li>假设我们想要训练这样一个卷积网络：它包含步幅为s的步幅卷积，该卷积的核为K，作用于多通道的图像V，定义为$c(K,V,s)$。 </li>
		<li>假设我们想要最小化某个损失函数$J(V,K)$。 </li>
		<li>在前向传播过程中，我们需要用c本身来输出Z，然后Z传递到网络的其余部分并且被用来计算损失函数J。 </li>
		<li>在反向传播过程中，我们会得到一个张量G满足：$G_{i,j,k}=\frac{∂}{∂Z_{i,j,k}}J(V,K)$。 </li>
		<li>核参数的更新规则：$\frac{∂}{∂K_{i, j, k, l}} J(V, K) = \sum_{m, n} G_{i, m, n} V_{j, (m-1)× s+k, (n-1)× s+l}$。</li>
		</ul>
		<p><strong>卷积网络的神经科学基础</strong>：</p>
		<ul>
		<li>卷积网络也许是生物学启发人工智能的最为成功的案例。 </li>
		<li>神经生理学家David Hubel和Torsten Wiesel观察了猫的脑内神经元如何响应投影在猫前面屏幕上精确位置的图像。 </li>
		<li>他们的伟大发现是：处于视觉系统较为前面的神经元对非常特定的光模式（例如精确定向的条纹）反应最强烈，但对其他模式几乎完全没有反应。 </li>
		</ul>
		<h1 id="10.-Sequence-Modeling:-Recurrent-and-Recursive-Nets">10. Sequence Modeling: Recurrent and Recursive Nets<a class="anchor-link" href="#10.-Sequence-Modeling:-Recurrent-and-Recursive-Nets">¶</a></h1><p><strong>循环神经网络（Recurrent Neural Network，RNN）</strong>：</p>
		<ul>
		<li>是一类用于处理<strong>序列数据</strong>的神经网络。 </li>
		<li>RNN在不同的时间点上<strong>共享参数</strong>，使得模型能够扩展到<strong>不同长度</strong>的样本并进行泛化。</li>
		<li>如果我们在每个时间点都有一个单独的参数，我们不但不能泛化到训练时没有见过序列长度，也不能在时间上共享不同序列长度和不同位置的统计强度。</li>
		<li>$h^{(t)} = f (h^{(t−1)}, x^{(t)} ; θ)$</li>
		</ul>
		<p><strong>展开过程的两个主要优点</strong>：</p>
		<ul>
		<li>无论序列的长度，学成的模型始终具有相同的输入大小。</li>
		<li>可以在每个时间节点使用相同的转移函数$f$。</li>
		</ul>
		<p><strong>重要的几种设计模式</strong>：</p>
		<ul>
		<li>1.每个时间步都有输出，并且隐藏单元之间有循环连接的循环网络；</li>
		<li>2.每个时间步都产生一个输出，只有当前时刻的输出到下个时刻的隐藏单元之间有循环连接的循环网络；</li>
		<li>3.隐藏单元之间存在循环连接，但读取整个序列后产生单个输出的循环网络。</li>
		</ul>
		<p><strong>典型的RNN</strong>：</p>
		<ul>
		<li><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/rnn.png" /></li>
		<li>$a^{(t)}=b+Wh^{(t−1)}+Ux^{(t)}$</li>
		<li>$h^{(t)}=tanh(a^{(t)})$</li>
		<li>$o^{(t)}=c+Vh^{(t)}$</li>
		<li>$y^{(t)}=softmax(o^{(t)})$</li>
		<li>$\theta = \{W,U,V,b,c\}$，其中，$b,c$是偏置参数向量。</li>
		<li>$L^{(t)}$是给定$x^{(1)}, x^{(2)}, ..., x^{(t)}$后$y^{(t)}$的<strong>负似然对数</strong>。</li>
		<li>$L(\{x^{(1)}, x^{(2)}, ..., x^{(t)}\},\{y^{(1)}, y^{(2)}, ..., y^{(t)}\})\\=\sum_t L^{(t)}\\=-\sum_tlogp_{model}(y^{(t)}|x^{(1)}, x^{(2)}, ..., x^{(t)})$</li>
		<li>应用于展开图的反向传播算法被称为<strong>通过时间反向传播（back-propagation through time, BPTT）</strong>。</li>
		</ul>
		<p><strong>Teacher Forcing</strong>：</p>
		<ul>
		<li>每一步的输入包含上一步的输出意味着模型不能并行训练。 </li>
		<li>使用Teacher Forcing训练模型时，使用最大似然准则，而在时刻$t+1$接收真实值$y^{(t)}$作为输入: 条件最大似然准则是：$logp(y^{(1)},y^{(2)}∣x^{(1)},x^{(2)})=logp(y^{(2)}∣y^{(1)},x^{(1)},x^{(2)})+logp(y^{(1)}∣x^{(1)},x^{(2)})$</li>
		<li><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/teacher-forcing.png" /></li>
		</ul>
		<p><strong>确定序列的长度的方式</strong>：</p>
		<ul>
		<li>1.对于文本类的数据，添加一个对应于序列末端的特殊符号<code>EOS</code>；</li>
		<li>2.引入一个额外的Bernoulli输出，表示在每个时间步决定继续生成或停止生成，这个方法最<strong>通用</strong>D；</li>
		<li>3.将一个额外的输出添加到模型并预测长度$\tau$本身：$P(x^{(1)},…,x^{(τ)})=P(τ)P(x^{(1)},…,x^{(τ)}∣τ)$。</li>
		</ul>
		<p><strong>双向RNN（Bidirectional RNNs）</strong>：</p>
		<ul>
		<li>在许多应用中，我们要输出的$y^{(t)}$的预测可能依赖于整个输入序列，于是有了双向RNN。</li>
		<li><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/bi-rnn.png" /></li>
		</ul>
		<p><strong>编码-解码架构（Encoder-Decoder）</strong>：</p>
		<ul>
		<li>在一些应用中，我们需要将输入序列映射到不一定等长的输出序列，于是有了Encoder-Decoder。</li>
		<li>（1）编码器处理输入序列，编码器输出上下文$C$（通常是最终隐藏状态的简单函数）。</li>
		<li>(2）解码器则以固定长度的向量为条件产生输出序列$Y=(y^{(1)}, \dots, y^{(n_y)})$。</li>
		<li><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/en-de.png" /></li>
		</ul>
		<p><strong>递归神经网络（Recursive Neural Network）</strong>：</p>
		<ul>
		<li>它被构造为深的<strong>树状结构</strong>而不是RNN的链状结构，递归网络已成功地应用于输入是数据结构的神经网络，如自然语言处理和计算机视觉深度。 </li>
		<li>它的一大优势是对于具有相同长度$\tau$的序列，深度（通过非线性操作的组合数量来衡量）可以急剧地从$\tau$减小为$O(\log \tau)$，这可能有助于解决长期依赖。</li>
		<li><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/recursive-nn.png" /></li>
		</ul>
		<p><strong>长期依赖的挑战（Long-Term Dependencies）</strong>：问题描述：经过许多阶段传播后的梯度<strong>倾向于消失（大部分情况）</strong>或<strong>爆炸（很少，但对优化过程影响很大）</strong>。</p>
		<p><strong>解决方法</strong>：</p>
		<p><strong>1.回声状态网络（Echo State Networks）</strong>：</p>
		<ul>
		<li>从$h^{(t-1)}$到$h^{(t)}$的循环权重映射以及从$x^{(t)}$到$h^{(t)}$的输入权重映射是循环网络中最难学习的参数。 </li>
		<li>避免这种困难的方法是设定循环隐藏单元，使其能很好地捕捉过去输入历史，并且<strong>只学习输出权重</strong>。</li>
		</ul>
		<p><strong>2.多时间尺度的策略</strong>：</p>
		<ul>
		<li>设计工作在多个时间尺度的模型，使模型的某些部分在细粒度时间尺度上操作并能处理小细节，而其他部分在粗时间尺度上操作并能把遥远过去的信息更有效地传递过来。</li>
		<li>1.时间维度的跳跃连接（skip connection）：增加从遥远过去的变量到目前变量的直接连接是得到粗时间尺度的一种方法。</li>
		<li>2.渗漏单元（Leaky Units）：我们对某些$v$值应用更新$\mu^{(t)} \gets \alpha \mu^{(t-1)} + (1-\alpha) v^{(t)}$累积一个滑动平均值$\mu^{(t)}$，其中$\alpha$是一个从$ \mu^{(t-1)}$到$ \mu^{(t)}$线性自连接的例子。 当$\alpha$接近1时，滑动平均值能记住过去很长一段时间的信息，而当$\alpha$接近0，关于过去的信息被迅速丢弃。 线性自连接的隐藏单元可以模拟滑动平均的行为。 这种隐藏单元称为渗漏单元。3.删除连接：主动删除长度为一的连接并用更长的连接替换它们。</li>
		</ul>
		<p><strong>3.门控RNN</strong>：实际应用中<strong>最有效</strong>的序列模型，主要有LSTM和GRU。</p>
		<p><strong>LSTM</strong>：</p>
		<ul>
		<li>long short-term memory</li>
		<li>关键思想：<strong>自循环的权重视上下文而定，而不是固定的（普通的RNN是固定的W）。 </strong></li>
		<li>所谓的自循环的权重，<strong>由遗忘门控制。</strong></li>
		<li><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/lstm.png" /></li>
		<li>遗忘门：$f^{(t)}_i=σ(b^f_i+∑_jU^f_{i,j}x^{(t)}_j+∑_jW^f_{i,j}h^{(t−1)}_j)$</li>
		<li>输入门：$i^{(t)}_i=σ(b_i+∑_jU_{i,j}x^{(t)}_j+∑_jW_{i,j}h^{(t−1)}_j)$</li>
		<li>外部输入门（备选状态）：$g^{(t)}_i=σ(b^g_i+∑_jU^g_{i,j}x^{(t)}_j+∑_jW^g_{i,j}h^{(t−1)}_j)$</li>
		<li>内部状态：$s^{(t)}_i=f^{(t)}_is^{(t−1)}_i+g^{(t)}_ii^{(t)}_i$</li>
		<li>输出门：$h^{(t)}_i=tanh(s^{(t)}_i)q^{(t)}$，$q^{(t)}_i=σ(b^o_i+∑_jU^o_{i,j}x^{(t)}_j+∑_jW^o_{i,j}h^{(t−1)}_j)$。</li>
		</ul>
		<p><strong>LSTM vs. RNN and GRU</strong></p>
		<ul>
		<li>LSTM的自循环的权重视上下文而定，而不是固定的；而普通的RNN是固定的W。</li>
		<li>内部状态：<ul>
		<li>RNN：$h^{(t)}=\sigma(b+Wh^{(t−1)}+Ux^{(t)})$</li>
		<li>LSTM：$s^{(t)}_i=f^{(t)}_is^{(t−1)}_i+g^{(t)}_ii^{(t)}_i$，$g^{(t)}_i$又称为“备选状态”。</li>
		<li>GRU：$h^{(t)}_i=u^{(t−1)}_ih^{(t−1)}_i+(1−u^{(t−1)}_i)\tilde h_t$</li>
		<li>传统的RNN使用<strong>“覆写”</strong>的方式计算状态：$S_t=f(S_{t-1},x_t)$，根据求导的链式法则，这种形式直接导致梯度别表示成连积的形式，容易导致梯度消失或者梯度爆炸。</li>
		<li>现代的RNN（包括但不限于LSTM单元），使用<strong>“累加”</strong>的方式计算状态：$S_t = \sum_{\tau=1}^t\Delta S_{\tau}$，这种累加形式导致导数也是累加的形式，因此避免了梯度的消失。</li>
		</ul>
		</li>
		</ul>
		<p><strong>GRUs</strong>：</p>
		<ul>
		<li>与LSTM的主要区别是：单个门控单元同时控制遗忘因子和更新状态单元的决定。</li>
		<li>备选状态：$\tilde h_t = σ(b_i+∑_jU_{i,j}x^{(t)}_j+∑_jW_{i,j}r^{(t−1)}_jh^{(t−1)}_j)$</li>
		<li>$h^{(t)}_i=u^{(t−1)}_ih^{(t−1)}_i+(1−u^{(t−1)}_i)\tilde h_t$</li>
		<li>更新门：$u^{(t)}_i=σ(b^u_i+∑_jU^u_{i,j}x^{(t)}_j+∑_jW^u_{i,j}h^{(t)}_j)$</li>
		<li>复位门：$r^{(t)}_i=σ(b^r_i+∑_jU^r_{i,j}x^{(t)}_j+∑_jW^r_{i,j}h^{(t)}_j)$</li>
		</ul>
		<p><strong>截断梯度（Clipping Gradients）</strong>：</p>
		<ul>
		<li>强非线性函数（如由许多时间步计算的循环网络）往往倾向于非常大或非常小幅度的梯度。 </li>
		<li>目标函数（作为参数的函数）存在一个伴随”悬崖”的”地形”：宽且相当平坦区域被目标函数变化快的小区域隔开，形成了一种悬崖。 </li>
		<li>我们通常使用衰减速度足够慢的学习率，使连续的步骤具有大致相同的学习率。 </li>
		<li><strong>截断梯度是一个简单的解决方案</strong>：在参数更新之前截断梯度$g$的范数$||g||$：$if\;||g||&gt;v:\;\; g←\frac{gv}{||g||}$，其中$v$是参数梯度的阈值，是一个标量。 </li>
		<li>可以解决梯度爆炸问题。</li>
		<h2 id="11.-Practical-Methodology">11. Practical Methodology<a class="anchor-link" href="#11.-Practical-Methodology">¶</a></h2><p><strong>实践设计流程</strong>：1.确定目标：使用什么样的<strong>误差度量（error metric）</strong>，并为此指定目标值。2.尽快建立一个端到端的的pipeline，包括估计合适的性能度量（performance metric）。 3.搭建系统，并确定性能瓶颈，检查哪个部分的性能差于预期，以及是否是因为过拟合、欠拟合，或者数据或软件缺陷造成的。 4.根据具体观察反复地进行增量式的改动，如收集新数据、调整超参数或改进算法。</p>
		<p><strong>性能度量</strong>：如何确定合理的性能期望？ 在学术界，可以根据先前公布的<strong>基准结果（benchmark）</strong>来估计预期错误率；在现实世界中，一个应用的错误率有必要是安全的、具有成本效益的或吸引消费者的。 种类：<strong>1.正确率（accuracy）</strong>；<strong>2.准确率（precision）</strong>：是指预测结果属于某一类的个体，实际属于该类的比例；<strong>3.召回率（recall）</strong>：被正确预测为某类的个体，与数据集中该类个体总数的比例；<strong>4.F Score</strong>：$F = \frac{2pr}{p+r}$；<strong>5.覆盖（coverage）</strong>：机器学习系统能够产生响应的样本所占的比率，个系统可以通过拒绝处理任意样本的方式来达到$100\%$的精度，但是覆盖降到了$0\%$；</p>
		<p><strong>默认的基准（baseline）模型</strong>：1.首先，根据数据的结构选择一类合适的模型。 如果项目是以固定大小的向量作为输入的监督学习，那么可以使用全连接的前馈网络。 如果输入有已知的拓扑结构（例如，输入是图像），那么可以使用卷积网络。 2.选择优化方法：具有衰减学习率以及动量的SGD是优化算法一个合理的选择；另一个非常合理的选择是Adam算法。 3.除非训练集包含数千万以及更多的样本，否则项目应该在一开始就包含一些温和的正则化，提前终止也被普遍采用；Dropout也是一个很容易实现，且兼容很多模型和训练算法的出色正则化项；批标准化有时也能降低泛化误差，此时可以省略Dropout步骤。</p>
		<p><strong>是否使用无监督学习？</strong>在某些领域，比如自然语言处理，能够大大受益于无监督学习技术，如学习无监督词嵌入；在其他领域，如计算机视觉，除非是在半监督的设定下（标注样本数量很少），目前无监督学习并没有带来益处。</p>
		<p><strong>决定是否收集更多数据</strong>：1.首先，确定训练集上的性能是否可接受：如果模型在训练集上的性能就很差，学习算法都不能在训练集上学习出良好的模型，那么就没必要收集更多的数据，可以尝试增加更多的网络层或每层增加更多的隐藏单元，以增加模型的规模。 2.如果训练集上的性能是可接受的，那么我们开始度量测试集上的性能。 如果测试集上的性能也是可以接受的，那么就顺利完成了。 3.如果测试集上的性能比训练集的要差得多，那么收集更多的数据是最有效的解决方案之一。</p>
		<p><strong>调整超参数</strong>：1.手动：手动搜索超参数的主要目标是调整模型的有效容量以匹配任务的复杂性；学习率可能是最重要的超参数；如果你只有时间调整一个超参数，那就调整学习率；如果训练集错误率大于目标错误率，那么只能增加模型容量以改进模型，如果测试集错误率大于目标错误率,可以改变正则化超参数，以减少有效的模型容量。2.自动：网格搜索（grid search）：当有三个或更少的超参数时，常见的超参数搜索方法是网格搜索。 对于每个超参数，使用者选择一个较小的有限值集去探索。 然后，这些超参数笛卡尔乘积得到一组组超参数，网格搜索使用每组超参数训练模型。 挑选验证集误差最小的超参数作为最好的超参数，通常，网格搜索会在对数尺度下挑选合适的值，如{0.1,1,10}。随机搜索：首先，我们为每个超参数定义一个边缘分布，例如，Bernoulli分布或多项式分布（分别对应着二元超参数或离散超参数），或者对数尺度上的均匀分布（对应着正实值超参数）。
		<img alt="" src="https://github.com/applenob/reading_note/raw/master/res/hyperparameter.png" /></p>
		<p><strong>调试策略</strong>：1.可视化计算中模型的行为：当训练模型检测图像中的对象时，查看一些模型检测到部分重叠的图像；在训练语音生成模型时，试听一些生成的语音样本。 直接观察机器学习模型运行其任务，有助于确定其达到的量化性能数据是否看上去合理。 
		2.可视化最严重的错误： 通过查看训练集中很难正确建模的样本，通常可以发现该数据预处理或者标记方式的问题。 
		3.根据训练和测试误差检测软件： 我们往往很难确定底层软件是否是正确实现。 训练和测试误差能够提供一些线索。 如果训练误差较低，但是测试误差较高，那么很有可能训练过程正常运行，但模型由于算法原因过拟合了。 另一种可能是，测试误差没有被正确地度量，可能是由于训练后保存模型再重载去度量测试集时出现问题，或者是因为测试数据和训练数据预处理的方式不同。 如果训练和测试误差都很高，那么很难确定是软件错误，还是由于算法原因模型欠拟合。 这种情况需要进一步的测试，如下面所述。
		4.拟合极小的数据集： 当训练集上有很大的误差时，我们需要确定问题是真正的欠拟合，还是软件错误。 通常，即使是小模型也可以保证很好地拟合一个足够小的数据集。 例如，只有一个样本的分类数据可以通过正确设置输出层的偏置来拟合。 通常，如果不能训练一个分类器来正确标注一个单独的样本，或不能训练一个自编码器来成功地精准再现一个单独的样本，或不能训练一个生成模型来一致地生成一个单独的样本，那么很有可能是由于软件错误阻止训练集上的成功优化。 
		5.比较反向传播导数和数值导数： 如果使用一个需要实现梯度计算的软件框架，或者在添加一个新操作到求导库中，必须定义它的bprop方法，那么常见的错误原因是没能正确地实现梯度表达。 验证这些求导正确性的一种方法是比较实现的自动求导和通过有限差分计算的导数。 
		6.监控激活函数值和梯度的直方图： 可视化神经网络在大量训练迭代后（也许是一轮）收集到的激活函数值和梯度的统计量往往是有用的。 隐藏单元的预激活值可以告诉我们该单元是否饱和，或者它们饱和的频率如何。</p>
		<p><strong>例子：实现多位数字识别的街景转录系统</strong>：1.首先要采集数据：街景车收集原始数据，然后操作员手动提供标签。 2.目标是达到人类水平，$98\%$的准确率。 为了达到这个级别的准确率，街景转录系统牺牲了覆盖。 因此在保持准确率 $98\%$的情况下，覆盖成了这个项目优化的主要性能度量。 随着卷积网络的改进，我们能够降低网络拒绝转录输入的置信度阈值，最终超出了覆盖 $95\%$的目标。 3.快速建立一个合理的基准系统。 对于视觉任务而言，基准系统是带有整流线性单元（relu）的卷积网络。 4.当输出序列的概率低于某个值$t$即$p(y\mid x) < t$时，网络拒绝为输入$x$分类。 5.覆盖仍低于$90\%$，但该方法没有明显的理论问题了。 因此，我们的方法论建议综合训练集和测试集性能，以确定问题是否是欠拟合或过拟合。 在这种情况下，训练和测试集误差几乎是一样的。 因为训练和测试集的误差是如此相似，这表明要么是这个问题欠拟合，要么是训练数据的问题。 我们使用了推荐的调试策略之一，即<strong>可视化模型最糟糕的错误</strong>。 结果显示，主要是输入图像裁剪得太紧，有些和地址相关的数字被裁剪操作除去了。 6.最终，系统达到了预设的目标。</p>
		<h2 id="12.-Application">12. Application<a class="anchor-link" href="#12.-Application">¶</a></h2><h3 id="计算机视觉">计算机视觉<a class="anchor-link" href="#计算机视觉">¶</a></h3><p><strong>计算机视觉的应用</strong>：计算机视觉的应用广泛：从复现人类视觉能力（比如识别人脸）到创造全新的视觉能力。</p>
		<p><strong>预处理</strong>：1.标准化：使得它们的像素都在相同并且合理的范围内，比如$[0,1]$或者$[-1,1]$。2.标准尺寸：裁剪或缩放图像以适应固定的尺寸。3.数据集增强：只对训练集做预处理，是减少大多数计算机视觉模型泛化误差的一种极好方法。</p>
		<p><strong>对比度归一化</strong>：对比度指的是图像中亮像素和暗像素之间差异的大小，在深度学习中，对比度通常指的是图像或图像区域中像素的标准差。 <strong>全局对比度归一化</strong>旨在通过从每个图像中减去其平均值，然后重新缩放其使得其像素上的标准差等于某个常数$s$来防止图像具有变化的对比度。 局部对比度归一化确保对比度在每个小窗口上被归一化，而不是作为整体在图像上被归一化。</p>
		<p><strong>数据集增强</strong>：我们很容易通过增加训练集的额外副本来增加训练集的大小，进而改进分类器的泛化能力。 这些额外副本可以通过对原始图像进行一些变化来生成，但是并不改变其类别。 对象识别这个分类任务特别适合于这种形式的数据集增强，因为类别信息对于许多变换是不变的，而我们可以简单地对输入应用诸多几何变换。 分类器可以受益于<strong>随机转换或者旋转</strong>。 还有一些高级的用以数据集增强的变换，包括图像中<strong>颜色的随机扰动</strong>，以及对输入的<strong>非线性几何变形</strong>。</p>
		<h3 id="语音识别">语音识别<a class="anchor-link" href="#语音识别">¶</a></h3><p><strong>语音识别</strong>：语音识别任务旨在将一段包括了自然语言发音的声学信号投影到对应说话人的词序列上。</p>
		<p><strong>语音识别的应用</strong>：1.其中的一个创新点是卷积网络的应用。 卷积网络在时域与频域上复用了权重，改进了之前的仅在时域上使用重复权值的时延神经网络。 这种新的二维的卷积模型并不是将输入的频谱当作一个长的向量，而是当成是一个图像，其中一个轴对应着时间，另一个轴对应的是谱分量的频率。2.完全抛弃HMM转向研究端到端的深度学习语音识别系统是一大活跃领域，这个领域第一个主要的突破是一个深度的LSTM神经网络</p>
		<h3 id="自然语言处理">自然语言处理<a class="anchor-link" href="#自然语言处理">¶</a></h3><p><strong>自然语言处理</strong>：自然语言处理让计算机能够使用人类语言，例如英语或法语。</p>
		<p><strong>$n$-gram</strong>：语言模型定义了自然语言中标记序列的概率分布。 根据模型的设计，标记可以是词、字符、甚至是字节。 基于$n$-gram的模型定义一个条件概率——给定前$n-1$个标记后的第$n$个标记的条件概率。 该模型使用这些条件分布的乘积定义较长序列的概率分布：$P(x_1,…,x_τ)=P(x_1,…,x_{n−1})∏_{t=n}^τP(x_t∣x_{t−n+1},…,x_{t−1})$。 训练$n$-gram模型是简单的，因为最大似然估计可以通过简单地统计每个可能的$n$-gram在训练集中出现的次数来获得。 几十年来，基于$n$-gram的模型都是统计语言模型的核心模块。 通常我们同时训练~$n$-gram~模型和$n-1$ gram模型。 这使得下式可以简单地通过查找两个存储的概率来计算：$P(x_t∣x_{t−n+1},…,x_{t−1})=P_n(x_{t−n+1},…,x_t)P_{n−1}(x_{t−n+1},…,x_{t−1})$。 $n$-gram特别容易引起维数灾难。</p>
		<p><strong>神经语言模型</strong>：神经语言模型是一类用来克服维数灾难的语言模型，它使用词的分布式表示对自然语言序列建模。 不同于基于类的$n$-gram模型，神经语言模型在能够识别两个相似的词，并且不丧失将每个词编码为彼此不同的能力。</p>
		<p><strong>神经机器翻译</strong>：机器翻译以一种自然语言读取句子并产生等同含义的另一种语言的句子。 机器翻译系统通常涉及许多组件：在高层次，一个组件通常会提出许多候选翻译。 由于语言之间的差异，这些翻译中的许多翻译是不符合语法的。 翻译系统的第二个组成部分（语言模型）评估提议的翻译，并可以评估哪句翻译地更好。</p>
		<h3 id="其他应用">其他应用<a class="anchor-link" href="#其他应用">¶</a></h3><p><strong>推荐系统</strong>：可以分为两种主要的应用：在线广告和项目建议（通常这些建议的目的仍然是为了销售产品）。 两者都依赖于预测用户和项目之间的关联， 一旦向该用户展示了广告或推荐了该产品，推荐系统要么预测一些行为的概率（用户购买产品或该行为的一些代替）或预期增益（其可取决于产品的价值）。早期推荐系统的工作依赖于这些预测输入的最小信息：用户ID和项目ID。 在这种情况下，唯一的泛化方式依赖于不同用户或不同项目的目标变量值之间的模式相似性。 假设用户1和用户2都喜欢项目A，B和C. 由此，我们可以推断出用户1和用户2具有类似的口味。 如果用户1喜欢项目D，那么这可以强烈提示用户2也喜欢D。 基于此原理的算法称为<strong>协同过滤</strong>。 然而，协同过滤系统有一个基本限制：当引入新项目或新用户时，缺乏评级历史意味着无法评估其与其他项目或用户的相似性，或者说无法评估新的用户和现有项目的联系。 这被称为冷启动推荐问题。 解决冷启动推荐问题的一般方式是引入单个用户和项目的额外信息。 例如，该额外信息可以是用户简要信息或每个项目的特征。 使用这种信息的系统被称为基于内容的推荐系统(content-based recommender system)。 从丰富的用户特征或项目特征集到嵌入的映射可以通过深度学习架构学习。 专用的深度学习架构，如卷积网络已经应用于从丰富内容中提取特征，如提取用于音乐推荐的音乐音轨。 在该工作中，卷积网络将声学特征作为输入并计算相关歌曲的嵌入。 该歌曲嵌入和用户嵌入之间的点积则可以预测用户是否将收听该歌曲。</p>
		<p><strong>知识表示、推理和回答</strong>：数学中，二元关系是一组有序的对象对。 集合中的对具有这种关系，而那些不在集合中的对则没有。 例如，我们可以在实体集${ 1, 2, 3 }$上定义关系”小于”来定义有序对的集合$S = { (1, 2), (1, 3), (2, 3) }$。 一旦这个关系被定义，我们可以像动词一样使用它。 因为$(1, 2) \in S$，我们说1小于2。 一种常见的引入深度学习方法是将神经语言模型扩展到模型实体和关系。 神经语言模型学习提供每个词分布式表示的向量。 他们还通过学习这些向量的函数来学习词之间的相互作用，例如哪些词可能出现在词序列之后。 我们可以学习每个关系的嵌入向量将这种方法扩展到实体和关系。</p>
		<h2 id="13.-Linear-Factor-Models">13. Linear Factor Models<a class="anchor-link" href="#13.-Linear-Factor-Models">¶</a></h2><p><strong>线性因子模型（Linear Factor Models）</strong>：线性因子模型通过随机线性解码器函数来定义，该函数通过对h的线性变换以及添加噪声来生成x。通常包含如下步骤：1.首先，我们从一个分布中采样解释性因子h，$h\sim p(h)$，其中p(h)是一个因子分布，满足$p(h)=\prod_i p(h_i)$；2.然后，我们对实值的可观察变量进行采样$x=Wh+b+noise$。</p>
		<p><strong>概率PCA、因子分析和其他线性因子模型</strong>仅在对观测到x之前的噪声分布和隐变量h先验的选择上有所不同。</p>
		<p><strong>因子分析（Factor Analysis）</strong>：隐变量先验是一个方差为单位矩阵的高斯分布$h \sim N(h;0,I)$，同时假定在给定h的条件下观察值$x_i$是条件独立的。假设噪声是从对角协方差矩阵的高斯分布中采样的的，协方差矩阵为$ψ=diag(σ^2)$，容易看出，x服从多维正态分布，并满$x\sim N(x;b,WW^⊤+ψ)$。</p>
		<p><strong>概率PCA（Probabilistic PCA）和</strong>：在因子分析的基础上，使条件方差$σ^2_i$等于同一个值。x的协方差简化为$WW^⊤+σ^2_I$，或者等价的$x=Wh+b+σz$，其中$z\sim N(z;0,I)$</p>
		<p><strong>独立成分分析（Independent Component Analysis, ICA）</strong>：主要想法是：通过选择一个独立的p(h)，尽可能地恢复接近独立的潜在因子。每个训练样本对应一个时刻，每个$x_i$是一个传感器对混合信号的观察值，并且每个$h_i$是单个原始信号的一个估计。ICA的所有变种均要求p(h)是非高斯的。 这是因为如果p(h)是具有高斯分量的独立先验，则W是不可识别的。</p>
		<p><strong>慢特征分析（Slow Feature Analysis）</strong>：是使用来自时间信号的信息学习不变特征的线性因子模型。慢特征分析的想法源于所谓的慢性原则。 其基本思想是，与场景中起描述作用的单个量度相比，场景的重要特性通常变化得非常缓慢。为了引入慢性原则，我们可以向代价函数添加以下项:$λ\sum _tL(f(x^{(t+1)}),f(x^{(t)}))$。深度SFA已经被用于学习用在对象识别和姿态估计的特征。但是到目前为止，慢性原则尚未成为任何最先进应用的基础。究竟是什么因素限制了其性能仍有待研究，或许是慢度先验太过强势。</p>
		<p><strong>稀疏编码（Sparse Coding）</strong>：是一个线性因子模型，已作为一种无监督特征学习和特征提取机制得到了广泛研究。 严格来说，术语”稀疏编码”是指在该模型中推断h值的过程，而”稀疏建模”是指设计和学习模型的过程，但是通常这两个概念都可以用术语”稀疏编码”描述。 稀疏编码模型通常假设线性因子有一个各向同性精度为β的高斯噪声：$p(x∣h)=N(x;Wh+b,\frac{1}{β}I)$。分布p(h)通常选取为一个峰值仅在0点很尖锐的分布：$p(h_i)=Laplace(h_i;0,\frac{2}{λ})=\frac{λ}{4}e^{−\frac{1}{2}λ|h_i|}$。$h^*$的表达式里包含了$||h||_1$，这导致了$h^*$向量的稀疏性。</p>
		<h1 id="14.-Autoencoders">14. Autoencoders<a class="anchor-link" href="#14.-Autoencoders">¶</a></h1><h2 id="自编码器（Autoencoders）">自编码器（Autoencoders）<a class="anchor-link" href="#自编码器（Autoencoders）">¶</a></h2><p>自编码器是神经网络的一种，经过训练后能尝试将输入复制到输出。</p>
		<p>自编码器内部有一个隐藏层 $h$，产生<strong>编码表示输入</strong>。</p>
		<p>该网络由两部分组成：一个由函数$h = f(x)$表示的编码器和一个生成重构的解码器 $r=g(h)$。 如果一个自编码器只是简单地学会将处处设置为$g(f(x)) = x$，那么这个自编码器就没什么特别的用处。</p>
		<p>相反，我们不应该将自编码器设计成输入到输出完全相等:向自编码器强加一些约束，使它只能近似地复制，并只能复制与训练数据相似的输入。</p>
		<p><strong>这些约束强制模型考虑输入数据的哪些部分需要被优先复制，因此它往往能学习到数据的有用特性。</strong></p>
		<p>现代自编码器将编码器和解码器的概念推而广之，将确定函数推广为随机映射$p_{encoder} (h \mid x)$和$p_{decoder}(x \mid h)$。</p>
		<p>所有自编码器的训练过程涉及<strong>两种推动力</strong>的折衷：</p>
		<p>1.学习训练样本$x$的表示$h$使得$x$能通过解码器近似地从$h$中恢复，$x$是从训练数据挑出的这一事实很关键，因为这意味着在自编码器不需要成功重构不属于数据生成分布下的输入；</p>
		<p>2.满足约束或正则惩罚。 这可以是限制自编码器容量的架构约束，也可以是加入到重构代价的一个正则项。 两种推动力结合才是有用的，因为它们驱使隐藏的表示能捕获有关数据分布结构的信息。
		<img alt="" src="https://github.com/applenob/reading_note/raw/master/res/autoencoder.png" /></p>
		<p><strong>自编码器的应用</strong>：传统自编码器被用于<strong>降维</strong>或<strong>特征学习</strong>。 近年来，自编码器与潜变量模型理论的联系将自编码器带到了<strong>生成建模</strong>的前沿。</p>
		<h2 id="欠完备自编码器（Undercomplete-Autoencoder）">欠完备自编码器（Undercomplete Autoencoder）<a class="anchor-link" href="#欠完备自编码器（Undercomplete-Autoencoder）">¶</a></h2><p>从自编码器获得有用特征的一种方法是<strong>限制$h$的维度比$x$小</strong>，这种编码维度小于输入维度的自编码器称为欠完备自编码器。</p>
		<p>损失函数$L(x,g(f(x)))$，惩罚$g(f(x))$与$x$的差异，如均方误差。</p>
		<p>当解码器是线性的且$L$是均方误差，欠完备的自编码器会学习出与PCA相同的生成子空间。</p>
		<p>不幸的是，如果编码器和解码器被赋予过大的容量，自编码器会执行复制任务而捕捉不到任何有关数据分布的有用信息。</p>
		<h2 id="正则自编码器（Regularized-Autoencoders）">正则自编码器（Regularized Autoencoders）<a class="anchor-link" href="#正则自编码器（Regularized-Autoencoders）">¶</a></h2><p>使用的损失函数可以鼓励模型学习<strong>其他特性（除了将输入复制到输出）</strong>，而不必限制使用浅层的编码器和解码器以及小的编码维数来限制模型的容量。 这些特性包括<strong>稀疏表示</strong>、<strong>表示的小导数</strong>、以及<strong>对噪声或输入缺失的鲁棒性</strong>。</p>
		<h3 id="稀疏自编码器（Sparse-Autoencoders）">稀疏自编码器（Sparse Autoencoders）<a class="anchor-link" href="#稀疏自编码器（Sparse-Autoencoders）">¶</a></h3><p>训练时结合编码层的稀疏惩罚$\Omega(h)$和重构误差：$L(x,g(f(x)))+Ω(h)$。 其中， $Ω(h)=λ\sum_i|h_i|$一般用来学习特征，以便用于像分类这样的任务。</p>
		<h3 id="随机编码器和解码器（Stochastic-Encoders-and-Decoders）">随机编码器和解码器（Stochastic Encoders and Decoders）<a class="anchor-link" href="#随机编码器和解码器（Stochastic-Encoders-and-Decoders）">¶</a></h3><p>任何潜变量模型$p_{model}(h, x)$定义一个随机编码器：$p_{encoder}(h∣x)=p_{model}(h∣x)$，以及一个随机解码器：$p_{decoder}(x∣h)=p_{model}(x∣h)$。
		<img alt="" src="https://github.com/applenob/reading_note/raw/master/res/stochasticAutoencoder.png" /></p>
		<h3 id="去噪自编码器（Denoising-Autoencoders，DAE）">去噪自编码器（Denoising Autoencoders，DAE）<a class="anchor-link" href="#去噪自编码器（Denoising-Autoencoders，DAE）">¶</a></h3><p>使用损失函数：$L(x,g(f(\tilde x)))$，其中$\tilde x$是被某种噪声损坏的$x$的副本。</p>
		<p>引入损坏过程（corruption process）$C(\tilde{x} \mid x)$。</p>
		<p>训练过程：</p>
		<p>1.从训练数据中采一个训练样本$x$；</p>
		<p>2.从$C(\tilde{x} \mid x=x)$采一个<strong>损坏样本</strong>$\tilde x$；</p>
		<p>3.将$(x, \tilde x)$作为训练样本来估计自编码器的重构分布$p_{reconstruct} (x \mid \tilde x) = p_{decoder}(x \mid h)$，其中，$h$是编码器 $f(\tilde x)$的输出，$p_{decoder}$根据解码函数$g(h)$定义。</p>
		<p>通常我们可以简单地对<strong>负对数似然</strong>$-\log p_{decoder} (x \mid h)$进行基于梯度的近似最小化，因此，我们可以认为DAE是在以下期望下进行随机梯度下降：$E_{x \sim \hat{p}_{data}(x)} E_{\tilde{x} \sim C(\tilde{x}\mid x)} \log p_{decoder}(x \mid h = f(\tilde{x}))$，其中，$\hat{p}_{data}(x)$是训练数据的分布。</p>
		<p>对一类采用高斯噪声和均方误差作为重构误差的特定去噪自编码器（具有sigmoid隐藏单元和relu）的去噪训练过程，与训练带高斯可见单元的RBM无向概率模型是等价的。
		<img alt="" src="https://github.com/applenob/reading_note/raw/master/res/dae.png" /></p>
		<h3 id="流形（manifold）相关">流形（manifold）相关<a class="anchor-link" href="#流形（manifold）相关">¶</a></h3><p><strong>流形的一些重要特性</strong>：一个重要特征是<strong>切平面（tangent plane）</strong>：$d$维流形上的一点$x$，切平面由能张成流形上允许变动的局部方向的$d$维基向量给出。 $n$维流形在每个点处都具有$n$维切平面。 该切平面恰好在该点接触流形，并且在该点处平行于流形表面。 它定义了为保持在流形上可以移动的方向空间。</p>
		<p><strong>使用自编码器学习流形</strong>：自编码器的目标是学习流形的结构。 我们可以通过构建对数据点周围的输入扰动不敏感的重构函数，使得自编码器恢复流形结构。 <img alt="" src="https://github.com/applenob/reading_note/raw/master/res/manifold.png" /></p>
		<h3 id="收缩自编码器（Contractive-Encoder）">收缩自编码器（Contractive Encoder）<a class="anchor-link" href="#收缩自编码器（Contractive-Encoder）">¶</a></h3><p><strong>惩罚导数作为正则</strong>：$L(x,g(f(x)))+Ω(h,x)$，其中，$Ω(h,x)=λ∑_i||∇_xh_i||^2$。 这迫使模型学习一个在$x$变化小时目标也没有太大变化的函数。</p>
		<p>鼓励$f$的导数尽可能小：$Ω(h)=λ|\frac{∂f(x)}{∂x}|_F^2$。 惩罚项$\Omega(h)$为平方Frobenius范数（元素平方之和），作用于与编码器的函数相关偏导数的Jacobian矩阵。</p>
		<h2 id="15.-Representation-Learning">15. Representation Learning<a class="anchor-link" href="#15.-Representation-Learning">¶</a></h2><p><strong>前馈网络</strong>：我们可以将监督学习训练的前馈网络视为表示学习的一种形式。 具体地，网络的最后一层通常是线性分类器，如softmax回归分类器。 网络的其余部分学习出该分类器的表示。</p>
		<p><strong>贪心逐层无监督预训练（Greddy Layer-Wise Unsupervised Pretrain）</strong>：贪心逐层无监督预训练依赖于单层表示学习算法，例如RBM、单层自编码器、稀疏编码模型或其他学习潜在表示的模型。 每一层使用无监督学习预训练，将前一层的输出作为输入，输出数据的新的表示。 贪心逐层无监督预训练被称为贪心的，是因为它是一个贪心算法， 这意味着它独立地优化解决方案的每一个部分，每一步解决一个部分，而不是联合优化所有部分。 它被称为逐层的，是因为这些独立的解决方案是网络层。 具体地，贪心逐层无监督预训练每次处理一层网络，训练第kk层时保持前面的网络层不变。无监督预训练结合了两种不同的想法： 第一，它利用了深度神经网络对初始参数的选择，可以对模型有着显著的正则化效果（在较小程度上，可以改进优化）的想法。 第二，它利用了更一般的想法——学习输入分布有助于学习从输入到输出的映射。
		<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/greedy_pre.png" />
		从无监督预训练作为学习一个表示的角度来看，我们可以期望无监督预训练在初始表示较差的情况下更有效，一个重要的例子是词嵌入。 从无监督预训练作为正则化项的角度来看，我们可以期望无监督预训练在标注样本数量非常小时很有帮助。 大部分算法已经不使用无监督预训练了，但是在自然语言处理领域中单词作为one-hot向量的表示不能传达相似性信息，并且有非常多的未标注数据集可用。</p>
		<p><strong>迁移学习（transfer learning）和领域自适应（domain adaption）</strong>：指的是利用一个情景（例如，分布P1）中已经学到的内容去改善另一个情景（比如分布P2）中的泛化情况。 在迁移学习中，学习器必须执行两个或更多个不同的任务，但是我们假设能够解释P1变化的许多因素和学习P2需要抓住的变化相关。比如，许多视觉类别<strong>共享</strong>一些低级概念，比如边缘、视觉形状、几何变化、光照变化的影响等等。 在领域自适应的相关情况下，在每个情景之间任务（和最优的输入到输出的映射）都是相同的，但是输入分布稍有不同。</p>
		<p><strong>一次学习（one shot learning）</strong>： 只有一个标注样本的迁移任务被称为一次学习，第一阶段学习出的表示就可以清楚地分离出潜在的类别，所以一次学习是可能的。 在迁移学习阶段，仅需要一个标注样本来推断表示空间中聚集在相同点周围许多可能测试样本的标签。</p>
		<p><strong>零次学习（zero shot learning）</strong>：没有标注样本的迁移任务被称为零次学习，例子：一个学习器已经读取了大量文本，然后要解决对象识别的问题。 如果文本足够好地描述了对象，那么即使没有看到某对象的图像，也能识别出该对象的类别。 例如，已知猫有四条腿和尖尖的耳朵，那么学习器可以在没有见过猫的情况下猜测该图像中是猫。</p>
		<p><strong>”什么原因能够使一个表示比另一个表示更好？”</strong>：这是表示学习的一个重要问题。一种假设是，理想表示中的特征对应到观测数据的潜在成因，特征空间中不同的特征或方向对应着不同的原因，从而表示能够区分这些原因。</p>
		<h1 id="16.-Structured-Probabilistic-Models-for-Deep-Learning">16. Structured Probabilistic Models for Deep Learning<a class="anchor-link" href="#16.-Structured-Probabilistic-Models-for-Deep-Learning">¶</a></h1><h2 id="多样化的任务：">多样化的任务：<a class="anchor-link" href="#多样化的任务：">¶</a></h2><p>除了分类任务以外，很多任务需要<strong>对输入数据整个结构有完整理解</strong>，包括：</p>
		<p>1.<strong>概率密度估计（Density Estimation）</strong>：给定一个输入x，机器学习系统返回一个对数据生成分布的真实密度函数p(x)的估计。</p>
		<p>2.<strong>去噪（Denoising）</strong>：给定一个受损的或者观察有误的输入数据$\tilde{x}$，机器学习系统返回一个对原始的真实x的估计。</p>
		<p>3.<strong>缺失值的填补（Missing Value Imputation）</strong>：给定x的某些元素作为观察值，模型被要求返回一些或者全部未观察值的估计或者概率分布。</p>
		<p>4.<strong>采样（Sampling）</strong>：模型从分布$p(x)$中抽取新的样本。</p>
		<h2 id="非结构化建模的挑战">非结构化建模的挑战<a class="anchor-link" href="#非结构化建模的挑战">¶</a></h2><p>如果我们希望对一个包含$n$个离散变量并且每个变量都能取$k$个值的$x$的分布建模，那么最简单的表示$P(x)$的方法需要存储一个可以查询的表格。 
		这个表格记录了每一种可能值的概率，则需要$k^n$个参数。</p>
		<p>非结构化建模不可行的原因：</p>
		<p><strong>1.内存</strong>：前面提到的存储参数的开销。</p>
		<p><strong>2.统计的有效性</strong>：当模型中的参数个数增加时，使用统计估计器估计这些参数所需要的训练数据数量也需要相应地增加。 因为基于查表的模型拥有天文数字级别的参数，为了准确地拟合，相应的训练集的大小也是相同级别的。</p>
		<p><strong>3.运行时间：推断的开销。</strong>比如推断边缘分布$P(x_1)$或者条件分布$P(x_2∣x_1)$。 计算这样的分布需要对整个表格的某些项进行求和操作，开销也很大。</p>
		<p><strong>4.运行时间：采样的开销。</strong>最简单的方法就是从均匀分布中采样，$u∼U(0,1)$，然后把表格中的元素累加起来，直到和大于u，然后返回最后一个加上的元素。 最差情况下，这个操作需要读取整个表格。</p>
		<p><strong>本质问题</strong>：基于表格操作的方法的主要问题是我们显式地对每一种可能的变量子集所产生的每一种可能类型的相互作用建模。 在实际问题中我们遇到的概率分布远比这个简单。 通常，许多变量只是间接地相互作用。</p>
		<h3 id="接力跑问题">接力跑问题<a class="anchor-link" href="#接力跑问题">¶</a></h3><p>对接力跑步比赛中一个队伍完成比赛的时间进行建模。</p>
		<p>假设这个队伍有三名成员：Alice， Bob和Carol，分别对应1/2/3棒。</p>
		<p>如果我们已经知道了Bob的完成时间，知道Alice的完成时间对估计Carol的完成时间并无任何帮助。</p>
		<p>这意味着我们可以通过<strong>两个相互作用</strong>来建模这个接力赛。</p>
		<p>即，我们可以忽略第三种间接的相互作用，即Alice的完成时间对Carol的完成时间的影响。</p>
		<p><strong>用接力跑问题分析非结构化建模的问题</strong>：如果我们把10分钟分为100份，那么三个离散随机变量$t_1$，$t_2$，$t_3$都有100种可能值。于是，非结构化建模要表示$p(t_0,t_1,t_2)$需要保存999999种可能值。</p>
		<h2 id="图模型">图模型<a class="anchor-link" href="#图模型">¶</a></h2><p>图模型的每个结点表示一个随机变量，每条边表示一个直接相互作用（direct interaction）。</p>
		<h3 id="有向图模型（Directed-Graphical-Model）">有向图模型（Directed Graphical Model）<a class="anchor-link" href="#有向图模型（Directed-Graphical-Model）">¶</a></h3><p>有向图模型是一种结构化概率模型，也被称为<strong>信念网络（Belief Network）</strong>或者<strong>贝叶斯网络（Baysian Network）</strong>。<strong>箭头所指的方向</strong>表示了<strong>这个随机变量的概率分布是由其他变量的概率分布所定义的</strong>。</p>
		<p>画一个从结点$a$到结点$b$的箭头表示了我们用一个条件分布来定义b，而a是作为这个条件分布符号右边的一个变量。</p>
		<p>正式地说，变量$x$的有向概率模型是通过有向无环图$G$和一系列局部条件概率分布$p(x_i∣Pa_G(x_i))$来定义的，其中$Pa_G(x_i)$表示结点$x_i$的所有父结点。</p>
		<p>$x$的概率分布可以表示为$p(x)=\underset{i}{∏}p(x_i∣Pa_G(x_i))$。通常意义上说，对每个变量都能取$k$个值的$n$个变量建模，基于建表的方法需要的复杂度是$O(k^n)$。</p>
		<p>但如果用一个有向图模型来对这些变量建模：<strong>$m$代表图模型的单个条件概率分布中最大的变量数目（包括在条件符号的左和右）</strong>，那么对这个有向模型建表的复杂度大致$O(k^m)$。 只要我们在设计模型时使其满足$m≪n$，那么复杂度就会被大大地减小。</p>
		<p><strong>有向图模型描述接力跑问题</strong>：$p(t_0,t_1,t_2)=p(t_0)p(t_1∣t_0)p(t_2∣t_1)$。那么，记录$t_0$的分布需要存储99个值，给定$t_0$情况下$t_1$的分布需要存储9900个值，给定$t_1$情况下$t_2$的分布也需要存储9900个值。 加起来总共需要存储19,899个值。 这意味着使用有向图模型将参数的个数减少了超过50倍！
		<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/race.png" /></p>
		<h3 id="感冒生病问题">感冒生病问题<a class="anchor-link" href="#感冒生病问题">¶</a></h3><p>你是否生病，你的同事是否生病以及你的室友是否生病。</p>
		<h3 id="无向图模型（Undirected-Graphical-Model）">无向图模型（Undirected Graphical Model）<a class="anchor-link" href="#无向图模型（Undirected-Graphical-Model）">¶</a></h3><p>无向模型，也被称为<strong>马尔可夫随机场（Markov random fields， MRFs）</strong>或者是<strong>马尔可夫网络（Markov networks）</strong>。</p>
		<p>当相互的作用并没有本质性的指向，或者是明确的双向相互作用时，使用无向模型更加合适。</p>
		<p>正式地说，一个无向模型是一个定义在无向模型G上的结构化概率模型。</p>
		<p>对于图中的每一个团C，<strong>一个因子（factor）$ϕ(C)$(也称为团势能)</strong>，衡量了团中变量每一种可能的联合状态所对应的密切程度。这些因子都被限制为是非负的。</p>
		<p>它们一起定义了未归一化概率函数：$\tilde{p}(x)=_{C∈G}ϕ(C)$。</p>
		<p>只要所有团中的结点数都不大，那么我们就能够高效地处理这些未归一化概率函数</p>
		<p><strong>无向图描述感冒生病问题</strong>：假设你的室友和同事并不认识，所以他们不太可能直接相互传染一些疾病，比如说感冒。 这个事件太过罕见，所以我们不对此事件建模。 然而，很有可能其中之一将感冒传染给你，然后通过你再传染给了另一个人。你健康状况的随机变量记作$h_y$，对应你的室友健康状况的随机变量记作$h_r$，你的同事健康的变量记作$h_c$。
		<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/cold.png" />
		因子（团势能）：
		<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/factor.png" /></p>
		<p><strong>配分函数（Partition Function）</strong>：因为$\tilde{p}(x)$是为归一化的概率，于是$p(x)=\frac{1}{Z}\tilde{p}(x)$。 <strong>归一化常数Z被称作是配分函数</strong>，是关于参数Θ的函数，这是一个从统计物理学中借鉴的术语。 <strong>由于Z通常是由对所有可能的x状态的联合分布空间求和或者求积分得到的，它通常是很难计算的。</strong> 在深度学习中，$Z$通常是难以处理的。 由于$Z$难以精确地计算出，我们只能使用一些近似的方法。</p>
		<p><strong>基于能量的模型（Energy-Based-Models）</strong>：无向模型中许多有趣的理论结果都依赖于$∀x, \tilde{p}(x)>0$，这个假设。 使这个条件满足的一种简单方式是使用基于能量的模型，其中$\tilde{p}(x)=exp(−E(x))$，$E(x)$被称作是能量函数。 对所有的$z$，$exp⁡(z)$都是正的，这保证了没有一个能量函数会使得某一个状态$x$的概率为0。 服从上面形式的任意分布都是玻尔兹曼分布的一个实例，基于这个原因，<strong>我们把许多基于能量的模型称为玻尔兹曼机。</strong></p>
		<h3 id="分离（seperation）和d-分离（d-seperation）">分离（seperation）和d-分离（d-seperation）<a class="anchor-link" href="#分离（seperation）和d-分离（d-seperation）">¶</a></h3><p>图模型中的边告诉我们哪些变量直接相互作用。 同时，我们经常需要知道哪些变量间接相互作用。 也就是说，我们想知道在给定其他变量子集的值时，哪些变量子集彼此条件独立。</p>
		<p><strong>分离（seperation）</strong>：如果图结构显示给定变量集S的情况下变量集A与变量集B无关，那么我们声称给定变量集S时，变量集A与另一组变量集B是分离的。 连接两个变量a和b的连接路径<strong>只包含由未观察变量</strong>，那么这些变量不是分离的。 如果它们之间没有路径，或者所有路径都包含可观测的变量，那么它们是分离的。 只包含由未观察变量的路径是<strong>”活跃”（active）</strong>的，而包括可观察变量的路径称为”非活跃”（inactive）的。</p>
		<p><strong>d-分离（d-seperation）</strong>：“d”代表”依赖”的意思；有向图中d-分离的定义与无向模型中分离的定义相同：如果图结构显示给定变量集S时，变量集A与变量集B无关，那么我们认为给定变量集S时，变量集Ad-分离于变量集B。 如果两个变量之间存在活跃路径，则两个变量是依赖的，如果没有活跃路径，则为d-分离。 在有向网络中，确定路径是否活跃有点复杂。</p>
		<p><strong>判断有向图路径是否活跃的细节</strong>：两个变量之间存在活跃路径的四中情况：<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/d-sep.png" />
		下图中：a和b是d-seperated；给定c时，a和e是d-seperated；给定c时，d和e是d-seperated。给定c，a和b不是d-seperated；给定d，a和b不是d-seperated。
		<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/d-sep-2.png" /></p>
		<h3 id="有向模型到无向模型">有向模型到无向模型<a class="anchor-link" href="#有向模型到无向模型">¶</a></h3><p>有向模型能够使用一种无向模型无法完美表示的特定类型的子结构，这个子结构被称为<strong>不道德（immorality）</strong>。</p>
		<p>这种结构出现在当两个随机变量a和b都是第三个随机变量c的父结点，并且不存在任一方向上直接连接a和b的边时。</p>
		<p><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/d2ud.png" /></p>
		<h3 id="无向模型到有向模型">无向模型到有向模型<a class="anchor-link" href="#无向模型到有向模型">¶</a></h3><p>无向模型也可能包括有向模型不能完美表示的子结构：如果U包含长度大于3的环（loop），则有向图D不能捕获无向模型U所包含的所有条件独立性，除非该环还包含<strong>弦（chord）</strong>。</p>
		<p>环指的是由无向边连接的变量序列，并且满足序列中的最后一个变量连接回序列中的第一个变量。</p>
		<p>弦是定义环序列中任意两个非连续变量之间的连接。</p>
		<p>如果U具有长度为4或更大的环，并且这些环没有弦，我们必须在将它们转换为有向模型之前添加弦。</p>
		<p><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/ud2d.png" /></p>
		<h3 id="因子图（Factor-Graphs）">因子图（Factor Graphs）<a class="anchor-link" href="#因子图（Factor-Graphs）">¶</a></h3><p>因子图是从无向模型中抽样的另一种方法，它可以解决标准无向模型语法中图表达的模糊性。 些节点被绘制为圆形。 就像在标准无向模型中一样，这些节点对应于随机变量。 其余节点绘制为<strong>方块</strong>。 这些节点对应于未归一化概率函数的因子ϕ。</p>
		<p><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/factor-model.png" /></p>
		<h3 id="图模型的采样（Sampling）">图模型的采样（Sampling）<a class="anchor-link" href="#图模型的采样（Sampling）">¶</a></h3><p><strong>有向图模型</strong>的采样比较简单，称为<strong>“原始采样”（ancestral sampling）</strong>。</p>
		<p>始采样的基本思想是将图中的变量$x_i$使用拓扑排序，使得对于所有$i$和$j$，如果$x_i$是$x_j$的一个父亲结点，则$j$大于$i$。 然后可以按此顺序对变量进行采样。</p>
		<p>换句话说，我们可以首先采$x_1\sim P(x_1)$，然后采$x_2\sim P(x_2∣Pa_G(x_2))$，以此类推，直到最后我们从$P(x_n∣Pa_G(x_n))$中采样。</p>
		<p>从<strong>无向模型</strong>中抽取样本是一个成本很高的多次迭代的过程。 理论上最简单的方法是<strong>Gibbs采样</strong>。</p>
		<h3 id="结构化概率模型的深度学习方法">结构化概率模型的深度学习方法<a class="anchor-link" href="#结构化概率模型的深度学习方法">¶</a></h3><p>在图模型中，我们可以根据图模型的图而不是计算图来定义模型的深度。 如果从潜变量$h_i$到可观察变量的最短路径是$j$步，我们可以认为潜变量$h_j$处于深度j。</p>
		<p>我们通常将模型的深度描述为任何这样的$h_j$的最大深度。</p>
		<p>深度学习模型通常具有比可观察变量更多的潜变量。</p>
		<p>潜变量的设计方式在深度学习中也有所不同。</p>
		<p>另一个明显的区别是深度学习方法中经常使用的连接类型。</p>
		<p>深度图模型通常具有大的与其他单元组全连接的单元组，使得两个组之间的相互作用可以由单个矩阵描述。</p>
		<p>在深度学习中使用的模型倾向于将每个可见单元$v_i$连接到非常多的隐藏单元$h_j$上，从而使得h可以获得一个$v_i$的分布式表示。</p>
		<p>最后，图模型的深度学习方法的一个主要特征在于对未知量的较高容忍度。</p>
		<h3 id="图模型举例：受限玻尔兹曼机（Restricted-Boltzmann-Machine）简介">图模型举例：受限玻尔兹曼机（Restricted Boltzmann Machine）简介<a class="anchor-link" href="#图模型举例：受限玻尔兹曼机（Restricted-Boltzmann-Machine）简介">¶</a></h3><p>具体关于rbm的内容在第20章笔记。</p>
		<p>标准的RBM是具有二值的可见和隐藏单元的基于能量的模型，其能量函数为：$E(v,h)=−b^⊤v−c^⊤h−v^⊤Wh$，其中$b$,$c$和$W$都是无约束、实值的可学习参数。</p>
		<p>模型的一个重要方面是在<strong>任何两个可见单元之间或任何两个隐藏单元之间没有直接的相互作用（从图上理解即横向没有连线，因此称为”受限”）</strong>。 因此，有良好的性质$p(h∣v)=∏_ip(h_i∣v)$，以及$p(v∣h)=∏_ip(v_i∣h)$。</p>
		<p>对于二元的受限玻尔兹曼机，我们可以得到：
		$p(h_i=1∣v)=σ(v^⊤W:,i+b_i),p(h_i=0∣v)=1−σ(v^⊤W_{:,i}+b_i)$</p>
		<p><img alt="" src="https://github.com/applenob/reading_note/raw/master/res/rbm.png" /></p>
		<h2 id="17.-Monte-Carlo-Methods">17. Monte Carlo Methods<a class="anchor-link" href="#17.-Monte-Carlo-Methods">¶</a></h2><p><strong>随机算法</strong>：随机算法可以粗略地分为两类：拉斯维加斯算法（Las Vegas algorithms）和蒙特卡洛算法（Monte Carlo algorithms）。</p>
		<p><strong>拉斯维加斯算法（Las Vegas algorithms）</strong>：总是精确地返回一个正确答案（或者返回算法失败）。 该方法通常需要占用随机量的计算资源（一般指内存或运行时间）。</p>
		<p><strong>蒙特卡洛算法（Monte Carlo algorithms）</strong>：蒙特卡罗方法返回的答案具有随机大小的错误。 花费更多的计算资源（通常包括内存和运行时间）可以减少这种错误。 在任意固定的计算资源下， 蒙特卡罗算法可以得到一个近似解。</p>
		<p><strong>为什么要sampling？</strong>：1.有时我们使用它加速一些很费时却易于处理的求和估计；2.有时我们用sampling去近似一个难以处理的求和或积分；3.还有一些时候，sampling就是我们的目标，例如我们想训练一个可以从训练分布采样的模型。</p>
		<p><strong>蒙特卡洛采样的基础（Basics of Monte Carlo Sampling）</strong>：当求和和积分不能直接计算时，我们使用下面的idea：将求和和积分视作某个分布的期望：$s=∑_xp(x)f(x)=E_p[f(x)]$或者$s=∫p(x)f(x)dx=E_p[f(x)]$，然后用平均值去估计它：$\hat{s_n} = \frac{1}{n}\sum_{i=1}^{n}f(x^{(i)})$</p>
		<p><strong>重要性采样（Importance Sampling）</strong>：p(x)f(x)重写成：$p(x)f(x) = q(x)\frac{p(x)f(x)}{q(x)}$，于是，蒙特卡洛Sampling可以转换成重要性Sampling，即从$\hat{s_p} = \frac{1}{n}\sum_{i=1,x^{(i)}\sim p}^{n}f(x^{(i)})$转换成$\hat{s_q} = \frac{1}{n}\sum_{i=1,x^{(i)}\sim q}^{n}\frac {p(x^{(i)})f(x^{(i)})}{q(x^{(i)})}=\frac{1}{n}\sum_{i=1,x^{(i)}\sim q}^{n}w(x^{(i)})f(x^{(i)})$。其中可以把$w(x)=\frac{p(x)}{q(x)}$称为<strong>重要性权重（importance weight）</strong></p>
		<p><strong>马尔科夫链蒙特卡洛方法</strong>：在深度学习的内容中，有时候需要从目标分布$p_{model}(x)$中精确采样或者一个好的（方差较小的）重要采样分布q(x)，但是又有很多时候不能直接采样，比如使用无向图模型的时候。使用MCMC方法有一个前提：所有的可能状态的概率不能为0，即不可化简性（Irreducibility）。无向图使用的基于能量的模型（Energy Based Model， EBM）保证了这一点。 马尔科夫链（Markov Chain）的核心思想：从某个可取任意值的状态x出发。 随着时间的推移，我们随机地反复更新状态x。最终x成为了一个从近似p(x)中抽出的样本。在正式的定义中，马尔科夫链由一个随机状态x和一个转移分布$T(x′∣x)$定义而成，$T(x′∣x)$是一个概率分布，说明了给定状态x的情况下随机地转移到x′的概率。 运行一个马尔科夫链意味着根据转移分布$T(x′∣x)$采出的值x′来更新状态x。运行马尔科夫链直到它达到均衡分布的过程通常被称为马尔科夫链的磨合过程（burning in）。 mcmc方法抽样的两个连续的样本之间会高度相关，如果我们想要得到完全独立的样本，那么我们可以同时并行地运行多个马尔科夫链。深度学习的从业者们通常选取的马尔科夫链的数目和小批量中的样本数相近，然后从这些固定的马尔科夫链集合中抽取所需要的样本。 马尔科夫链的数目通常选为100。 还有另一个难点是我们无法预先知道马尔可夫链需要运行多少步才能到达均衡分布。 这段时间通常被称为混合时间（mixing time）。</p>
		<p><strong>吉布斯采样（Gibbs Sampling）</strong>：其中在基于能量的模型中从T(x′∣x)采样是通过选择一个变量$x_i$，然后从$p_{model}$中该点关于在无向图G（定义了基于能量的模型结构）中邻接点的条件分布中采样。 只要一些变量在给定相邻变量时是条件独立的，那么这些变量就可以被同时采样。</p>
		<p>这章可以参考之前的<a href="https://applenob.github.io/1_MCMC.html">另一篇关于MCMC的笔记</a>，或者直接参考<a href="http://www.cs.princeton.edu/courses/archive/spr06/cos598C/papers/AndrieuFreitasDoucetJordan2003.pdf">An Introduction to MCMC for Machine Learning</a>，这里是<a href="https://zhuanlan.zhihu.com/p/25610149">中文简易翻译版</a>。</p>
		<h2 id="18.-Confronting-the-Partition-Function">18. Confronting the Partition Function<a class="anchor-link" href="#18.-Confronting-the-Partition-Function">¶</a></h2><p><strong>配分函数（Partition Function）</strong>：许多概率模型（<strong>通常是无向图模型</strong>）由一个未归一化的概率分布$\tilde{p}(x,θ)$定义。 必须通过除以<strong>配分函数Z(θ)来归一化$\tilde{p}$</strong>，以获得一个有效的概率分布：$p(x;θ)=\frac{1}{Z(θ)}\tilde{p}(x;θ)$。 配分函数是未归一化概率所有状态的积分（对于连续变量）或求和（对于离散变量）：$∫\tilde{p}(x)dx$或者$∑_x\tilde{p}(x)$。对很多有趣的模型，以上积分或求和难以计算。 有些深度学习模型被设计成具有一个易于处理的归一化常数，或被设计成能够在不涉及计算p(x)p(x)的情况下使用。 然而，其他一些模型会直接面对难以计算的配分函数的挑战。</p>
		<p><strong>对数似然梯度（Log-Likelihood Gradient）</strong>：对数似然对参数的梯度具有一项对应于配分函数的梯度：$∇_θlogp(x;θ)=∇_θlog\tilde{p}(x;θ)−∇_θlogZ(θ)$，这是非常著名的正相（positive phase）和负相（negative phase）的分解。 对于保证所有的x都有p(x)>0的模型，我们可以用$exp(log\tilde{p}(x))$代替$\tilde{p}(x)$，$∇_θlogZ(θ)$可以化简成$E_{x\sim p(x)}∇_θlog\tilde{p}(x)$。 转换成这种形式后，我们自然可以考虑用蒙特卡洛法来近似这个期望。 在正相中，我们增大从数据中采样得到的$log\tilde{p}(x)$。 在负相中，我们通过降低从模型分布中采样的$log\tilde{p}(x)$来降低配分函数。
		<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/p-n-phase.png" /></p>
		<p><strong>基于MCMC的方法</strong>：</p>
		<p><strong>朴素的MCMC算法</strong>：该算法计算代价太高，实际上不可行。 但是是其他算法的思想基础。
		<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/18-1.png" />
		负相涉及到从模型分布中抽样，可以认为它在找模型信任度很高的点。 负相减少了这些点的概率，这些点一般被认为代表了模型不正确的信念。 还可以用“做梦”来帮助理解：我们的大脑维护了一个现实世界的概率模型。醒着的时候，当你经历真实的事件，相当于按照$\tilde{p}(x)$的梯度去完善这个模型；做梦相当于从这个概率模型里随机抽样，当你醒来发现这是梦，就会按照$\tilde{p}(x)$的负梯度去更新模型，因为你知道梦是假的。</p>
		<p><strong>对比散度（Contrastive Divergence，CD）算法</strong>：接下来寻找计算代价更低的替代算法。 朴素的MCMC算法的计算成本主要来自每一步的<strong>随机初始化</strong>磨合马尔可夫链。 一个自然的解决方法是<strong>初始化马尔可夫链为一个非常接近模型分布的分布</strong>，从而大大减少磨合步骤。 CD算法在每个步骤中初始化马尔可夫链为采样自数据分布中的样本。 缺点：它不能抑制远离真实训练样本的高概率区域。 这些区域在模型上具有高概率，但是在数据生成区域上具有低概率，被称为虚假模态（spurious modes）。 在训练诸如RBM的浅层网络时,CD算法是很有用的；但CD算法并不直接有助于训练更深的模型。
		<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/18-2.png" /></p>
		<p><strong>持续性对比散度（Persistent Contrastive Divergence，PCD）算法</strong>：又称<strong>随机最大似然（Stochastic Maximum Likelihood，SML）</strong>，不同于CD，它在每个梯度步骤中初始化马尔可夫链为<strong>先前梯度步骤的状态值</strong>。 因为每个马尔可夫链在整个学习过程中不断更新，而不是在每个梯度步骤中重新开始，马尔可夫链可以自由探索很远，以找到模型的所有峰值。 因此，SML比CD更不容易形成具有虚假模态的模型。 
		<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/18-3.png" /></p>
		<p><strong>伪似然（Pseudolikelihood）</strong>：伪似然基于以下观察：无向概率模型中很容易计算概率的比率：$\frac{p(x)}{p(y)}=\frac{\frac{1}{Z}\tilde{p}(x)}{\frac{1}{Z}\tilde{p}(y)}=\frac{\tilde{p}(x)}{\tilde{p}(y)}$。伪似然的目标函数使用条件概率：$∑_{i=1}^nlogp(x_i∣x_{−i})$。如果每个随机变量有k个不同的值，那么考虑边缘概率的计算，$\tilde{p}$需要k×n次估计，而计算配分函数需要$k^n$次估计。</p>
		<p><strong>得分匹配（Score Matching）</strong>：对数密度关于参数的导数$∇_xlogp(x)$，被称为其得分（Score）。$L(x, \theta) = \frac{1}{2} || ∇_x \log p_{model}(x; \theta) - ∇_x log p_{data} (x) ||_2^2$，用下面的式子估计：$ \tilde{L}(x,\theta)=\sum_{j=1}^n(\frac{\partial^2}{\partial x^2_j}logp_{model}(x;\theta)+\frac{1}{2}(\frac{\partial }{\partial x_j}logp_{model}(x;\theta))^2 )$</p>
		<p><strong>比率匹配（Ratio Matching）</strong>：比率匹配特别适用于二值数据。 比率匹配最小化以下目标函数在样本上的均值：$L^{(RM)}(x,θ)=∑_{j=1}{n}(\frac{1}{1+\frac{p_{model}(x;θ)}{p_{model}(f(x),j;θ)}}^2$。其中f(x,j)返回j处位值取反的x。 比率匹配使用了与伪似然估计相同的策略来绕开配分函数：配分函数会在两个概率的比率中抵消掉。</p>
		<p><strong>去噪得分匹配（Denoising Score Matching）</strong>：可以去拟合正则化的$p_{smoothed}(x)=∫p_{data}(y)q(x∣y)dy$，而不是拟合真实分布$p_{data}$。 分布q(x∣y)是一个损坏过程，通常在形成x的过程中会向y中添加少量噪声。</p>
		<p><strong>噪声对比估计（Noise-Contrastive Estimation，NCE）</strong>：噪声对比估计直接估计模型的概率分布：$\log p_{model} (x) = \log \tilde{p}_{model} (x; \theta) + c$，其中c是$−logZ(θ)$的近似。 噪声对比估计过程将c视为另一参数，使用相同的算法同时估计θ和c。 NCE将估计p(x)的无监督学习问题转化为学习一个概率二元分类器，其中一个类别对应模型生成的数据，另一个对应噪声生成的数据。 具体地：我们引入噪声分布$p_{noise}(x)$。 噪声分布应该易于估计和从中采样。 再构造一个联合x和新二值变量y的模型。 指定：$p_{joint}(y=1)=\frac{1}{2}$，有$p_{joint}(x∣y=1)=p_{model}(x)$和$p_{joint}(x∣y=0)=p_{noise}(x)$</p>
		<p><strong>直接估计配分函数</strong>：当我们需要评估模型，监控训练性能，和比较模型时，还是需要直接估计配分函数，我们可以考虑蒙塔卡洛的方法去估计它。 首先找到一个简单的提议分布（proposal distribution）：$p_0(x)=\frac{1}{Z_0}\tilde{p}_0(x)$，其在配分函数$Z_0$和未归一化分布$\tilde{p}_0(x)$上易于采样和估计。 那么：$Z_1=∫\tilde{p}_1(x)dx=∫\frac{p_0(x)}{p_0(x)}\tilde{p}_1(x)dx=Z_0∫p_0(x)\frac{\tilde{p}_1(x)}{\tilde{p}_0(x)dx}$，可以使用简单重要采样（importance sampling）来估计：$\hat{Z}_1=\frac{Z_0}{K}\sum_{k=1}^K\frac{\tilde{p}_1(x^{(k)})}{\tilde{p}_0(x^{(k)})}\;\;s.t.\;:\;x^{(k)}\sim p_0$</p>
		<p><strong>退火重要采样（Annealed Importance Sampling, AIS）</strong>：在$D_{KL}(p_0|p_1)$很大的情况下（即$p_0$和$p_1$之间几乎没有重叠），退火重要采样通过引入中间分布来缩小这种差距。 考虑分布序列$p_{η_0},…,p_{η_n}$，其中$0=η_0&lt;η_1&lt;⋯&lt;η_{n−1}&lt;η_n=1$，分布序列中的第一个和最后一个分别是p0和p1。 $\frac{Z_1}{Z_0}$写作$\frac{Z_1}{Z_0}=\prod_{j=0}^{n-1} \frac{Z_{η_{j+1}}}{Z_{η_j}}$。 如果对于所有的$0&le;j&le;n−10&le;j&le;n−1$，分布$p_{η_j}$和$p_{η_{j+1}}$足够接近，那么能够使用简单的重要采样来估计每个因子$\frac{Z_{η_{j+1}}}{Z_{η_j}}$，然后使用这些得到$\frac{Z_1}{Z_0}$的估计。 中间分布的一个通用和流行选择是使用目标分布p1和建议分布p0的加权几何平均：$p_{η_j}∝p^{η_j}_1p^{1−η_j}_0$。</p>
		<p><strong>桥式采样（Bridge Sampling）</strong>：桥式采样依赖于单个分布$p^∗$（被称为桥），在已知配分函数的分布$p_0$和分布$p_1$之间插值。 $\frac{Z_1}{Z_0} ≈ \frac{\sum_{k=1}^K \frac{ \tilde{p}*(x_0^{(k)}) }{ \tilde{p}_0(x_0^{(k)}) }} {\sum_{k=1}^K \frac{ \tilde{p}*(x_1^{(k)}) }{ \tilde{p}_1(x_1^{(k)}) }} $。 最优的桥式采样是$p^{(opt)}_∗(x)∝\frac{\tilde{p}_0(x)\tilde{p}_1(x)}{r\tilde{p}_0(x)+\tilde{p}_1(x)}$，其中$r=Z_1/Z_0$。可以从粗糙的r开始估计，然后使用得到的桥式采样逐步迭代以改进估计。</p>
		<h1 id="19.-Approximate-Inference">19. Approximate Inference<a class="anchor-link" href="#19.-Approximate-Inference">¶</a></h1><h2 id="推断（Inference）">推断（Inference）<a class="anchor-link" href="#推断（Inference）">¶</a></h2><p>我们通常使用<strong>推断</strong>这个术语来指代给定一些其他变量的情况下计算某些变量概率分布的过程。</p>
		<p>在深度学习中，通常我们有一系列<strong>可见变量v</strong>和一系列<strong>隐变量h</strong>。</p>
		<p>推断困难通常是指难以计算$p(h∣v)$或其期望。</p>
		<p>推断在最大似然学习的任务中往往是必需的。</p>
		<p>但是，大多数具有多层隐藏变量的图模型的后验分布都很难处理。</p>
		<p>因此需要想办法来实现<strong>近似推断</strong>。</p>
		<h2 id="面对有隐变量的概率模型的思路">面对有隐变量的概率模型的思路<a class="anchor-link" href="#面对有隐变量的概率模型的思路">¶</a></h2><p>这种情况下，目标是极大化观测数据（不完全数据）v关于参数θ的对数似然函数，即最大化：$L(θ)=logp(v;θ)=log\sum_hp(v,h;θ)=log(\sum_hp(h|v;θ)p(v;θ))$。</p>
		<p>或者在图模型中，为了使用最大似然估计，有：$logp(v)=E_{h\sim p(h|v)}[logp(h,v)-logp(h|v)]$。</p>
		<p>总之，计算推断，也就是$p(h|v)$是很有必要的。</p>
		<h2 id="把推断视作优化问题">把推断视作优化问题<a class="anchor-link" href="#把推断视作优化问题">¶</a></h2><p>精确推断问题可以描述为一个优化问题，计算一个$logp(v;θ)$的下界<strong>$L(v,θ,q)$</strong>（这个下界被称为<strong>证据下界，evidence lower bound，ELBO</strong>，另一个常用名称是负变分自由能，negative variational free energy）：$L(v,θ,q)=log⁡p(v;θ)−D_{KL}(q(h∣v)‖p(h∣v;θ))$，其中q是关于h的一个任意概率分布。</p>
		<p>可以化简成：$L(v,θ,q)=E_{h\sim q}[logp(h,v)]+H(q)$。</p>
		<p>对任意分布q的选择来说，L提供了似然函数的一个下界。</p>
		<p>越好地近似$p(h∣v)$的分布$q(h∣v)$，得到的下界就越紧。</p>
		<p><strong>将推断问题看作是找一个分布q使得L最大的过程。</strong></p>
		<h2 id="EM（Expectation-Maximization）算法">EM（Expectation Maximization）算法<a class="anchor-link" href="#EM（Expectation-Maximization）算法">¶</a></h2><p>本质上，EM并不是一个近似推断算法，而是一种<strong>能够学到近似后验的算法</strong>；但是这里EM也可以解决近似推断问题。</p>
		<p><strong>E步</strong>: 令$θ^{(0)}$表示在这一步开始时的参数值。</p>
		<p>对索引为i的训练样本$v^{(i)}$，$q(h^{(i)}∣v)=p(h^{(i)}∣v^{(i)};θ^{(0)})$。</p>
		<p>认为q是在当前参数$θ^{(0)}$下定义的函数，也就是如果我们改变θ，那么$p(h∣v;θ)$将会相应地变化，但是$q(h∣v)$还是不变并且等于$p(h∣v;θ^{(0)})$。</p>
		<p><strong>M步</strong>：使用选择的优化算法关于θ最大化：$∑_iL(v^{(i)},θ,q)$。</p>
		<p>这可以被看作通过<strong>坐标上升（coordinate ascending）算法</strong>来最大化L。</p>
		<p>在第一步中，我们更新分布q来最大化L，而在另一步中，我们更新θ来最大化L。</p>
		<h2 id="最大后验推断（MAP）">最大后验推断（MAP）<a class="anchor-link" href="#最大后验推断（MAP）">¶</a></h2><p>$h^∗=\underset{h}{argmax}p(h∣v)$。</p>
		<p>令分布q满足一个Dirac分布：$q(h∣v)=δ(h−μ)$。 这也意味着可以通过μ来完全控制分布q。</p>
		<p>转换成另一个优化问题：$μ^∗=\underset{μ}{argmax} logp(h=μ,v)$。</p>
		<p>使用类似EM算法的学习算法，还是轮流迭代两步，一步是用MAP推断估计出$h^*$，另一步是更新θ来增大$log p(h^*,v)$。</p>
		<p>MAP推断作为特征提取器以及一种学习机制被广泛地应用在了深度学习中，主要用于稀疏编码模型中。</p>
		<h1 id="20.-Deep-Generative-Models">20. Deep Generative Models<a class="anchor-link" href="#20.-Deep-Generative-Models">¶</a></h1><h2 id="玻尔兹曼机（Boltzmann-Machines）">玻尔兹曼机（Boltzmann Machines）<a class="anchor-link" href="#玻尔兹曼机（Boltzmann-Machines）">¶</a></h2><p>我们在d维二值随机向量$x∈\{0,1\}^d$上定义玻尔兹曼机：</p>
		<p>玻尔兹曼机是一种<strong>基于能量</strong>的模型，意味着我们可以使用能量函数定义联合概率分布： $P(x) = \frac{\exp(-E(x))}{Z}$，其中$E(x)$是能量函数，Z是确保$∑_xP(x)=1$的配分函数。</p>
		<p>玻尔兹曼机的能量函数如下给出： $E(x) = -x^TUx - b^Tx$，其中$U$是模型参数的“权重”矩阵，$b$是偏置向量。</p>
		<p>带隐变量的玻尔兹曼机：$E(v,h)=−v^⊤Rv−v^⊤Wh−h^⊤Sh−b^⊤v−c^⊤h$。</p>
		<p><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/rbms.png" />
		a是受限玻尔兹曼机，RBM；b是深度信念网络，DBN；c是深度玻尔兹曼机，DBM。</p>
		<h2 id="Hebbian学习规则">Hebbian学习规则<a class="anchor-link" href="#Hebbian学习规则">¶</a></h2><p>我们可以假定，反射活动的持续与重复会导致神经元稳定性的持久性提升。</p>
		<p>当神经元A的轴突与神经元B很近并参与了对B的重复持续的兴奋时，这两个神经元或其中一个便会发生某些生长过程或代谢变化，致使A作为能使B兴奋的细胞之一，它的效能增强了。</p>
		<p>这一理论经常会被总结为“一起激发的神经元连在一起”（Cells that fire together, wire together）。这段摘自wikipedia。</p>
		<h2 id="受限玻尔兹曼机（Restricted-Boltzmann-Machine）">受限玻尔兹曼机（Restricted Boltzmann Machine）<a class="anchor-link" href="#受限玻尔兹曼机（Restricted-Boltzmann-Machine）">¶</a></h2><p>其能量函数为：$E(v,h)=−b^⊤v−c^⊤h−v^⊤Wh$，“受限”在于同层之间没有连接。</p>
		<p>使用训练具有难以计算配分函数的模型的技术来训练RBM。 这包括CD,SML（PCD）,比率匹配等。</p>
		<p>与深度学习中使用的其他无向模型相比，因为我们可以以闭解形式计算P(h∣v)，RBM可以相对直接地训练。</p>
		<h2 id="深度信念网络（Deep-Belief-Networks）">深度信念网络（Deep Belief Networks）<a class="anchor-link" href="#深度信念网络（Deep-Belief-Networks）">¶</a></h2><p>目前使用较少，但历史地位突出。 特点：顶部两层之间的连接是无向的。 而所有其他层之间的连接是有向的，箭头指向最接近数据的层。</p>
		<p>一个具有l个隐藏层的DBN包含l个权重矩阵：$W^{(1)},…,W^{(l)}$。</p>
		<p>同时也包含l+1个偏置向量： $b^{(0)},…,b^{(l)}$，其中$b^{(0)}$是可见层的偏置。</p>
		<p>DBN表示的概率分布由下式给出： $P(h^{(l)}, h^{(l-1)}) ∝ exp ( b^{(l)^T}h^{(l)} + b^{(l-1)^T}h^{(l-1)}+h^{(l-1)^T}W^{(l)}h^{(l)} )$，</p>
		<p>$P(h_i^{(k)} = 1 | h^{(k+1)}) = \sigma ( b_i^{(k)} + W_{:,i}^{(k+1)^T}h^{(k+1)} )~ \forall i, \forall k \in 1, ..., l-2$，</p>
		<p>$P(v_i = 1 | h^{(1)}) = \sigma ( b_i^{(0)} + W_{:,i}^{(1)^T}h^{(1)})~ \forall i $。</p>
		<p>在实值可见单元的情况下，替换$v∼N(v;b(0)+W(1)^⊤h(1),β−1)$。</p>
		<p>采样：先在顶部的两个隐藏层上运行几个Gibbs采样；再对后面的有向图进行ancestral采样。</p>
		
		<h2 id="深度玻尔兹曼机（Deep-Boltzmann-Machines）">深度玻尔兹曼机（Deep Boltzmann Machines）<a class="anchor-link" href="#深度玻尔兹曼机（Deep-Boltzmann-Machines）">¶</a></h2><p>特点：与DBN不同的是，它是一个完全无向的模型；与RBM不同的是，它有几层潜变量（RBM只有一层）。</p>
		<p>在一个深度玻尔兹曼机包含一个可见层v和三个隐藏层$h^{(1)},h^{(2)}和h^{(3)}$（$h^{(1)}$最靠近底层的可见层）的情况下，联合概率由下式给出：
		$P(v,h^{(1)},h^{(2)},h^{(3)})=\frac{1}{Z(θ)}exp(−E(v,h^{(1)},h^{(2)},h^{(3)};θ))$。</p>
		<p>能量函数：</p>
		<p>$E(v, h^{(1)},h^{(2)},h^{(3)}; \theta) = -v^⊤ W^{(1)}h^{(1)}-h^{(1)⊤}W^{(2)}h^{(2)}- h^{(2)⊤}W^{(3)}h^{(3)}$。</p>
		<p>条件概率：$P(v_i=1|h^{(1)})=σ(W_{i,:}^{(1)})$，$P(h_i^{(1)}|v,h^{(2)})=$</p>
		<p>$σ(v^⊤W_{:,i}^{(1)}+W_{i,:}^{(2)}h^{(2)})$，</p>
		<p>$P(h_k^{(2)}=1|h^{(1)})=σ(h^{(1)T}W_{:,k}^{(2)})$。</p>
		<p>二分图结构使Gibbs采样能在深度玻尔兹曼机中高效采样。</p>
		<p>有趣的性质：使用适当的均匀场允许DBM的近似推断过程捕获<strong>自顶向下反馈</strong>相互作用的影响。</p>
		<p>这从神经科学的角度来看是有趣的，人脑使用许多自上而下的反馈连接。</p>
		<p>DBM的一个<strong>缺点</strong>是采样时所有层都要使用MCMC。</p>
		<p><strong>均匀场估计</strong>：对于两层隐层的DBM，令$Q(h^{(1)},h^{(2)}∣v)$为$P(h^{(1)},h^{(2)}∣v)$的近似。</p>
		<p>均匀场假设意味着$Q(h^{(1)},h^{(2)}∣v)=∏_jQ(h^{(1)}_j∣v)∏_kQ(h^{(2)}_k∣v)$。</p>
		<p>将Q作为Bernoulli分布的乘积进行参数化：对于每个j，有$\hat h^{(1)}_j=Q(h^{(1)}_j=1∣v)$,其中$\hat h^{(1)}_j∈[0,1]$；</p>
		<p>对于每个k，有$\hat h^{(2)}_k=Q(h^{(2)}_k=1∣v)$，其中$\hat h^{(2)}_k∈[0,1]$。</p>
		<p>$Q(h^{(1)},h^{(2)}∣v)=∏_jQ(h^{(1)}_j∣v)∏_kQ(h^{(2)}_k∣v)$</p>
		<p>$=∏_j(\hat h^{(1)}_j)^{h^{(1)}_j}(1−\hat h^{(1)}_j)^{(1−h^{(1)}_j)}×∏_k(\hat h^{(2)}_k)^{h^{(2)}_k}(1−\hat h^{(2)}_k)^{(1−h^{(2)}_k)}$。</p>
		<p>更新规则：$\hat h_j^{(1)} = \sigma \Big( \sum_i v_i W_{i,j}^{(1)}+\sum_{k'}W_{j,k'}^{(2)} \hat h_{k'}^{(2)} \Big), ~~~~\forall j$，</p>
		<p>和$\hat h_{k}^{(2)} = \sigma \Big( \sum_{j'} W_{j',k}^{(2)} \hat h_{j'}^{(1)} \Big), ~~~~\forall k$。</p>
		<p><strong>参数学习</strong>：变分随机最大似然算法：</p>
		<p><img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/20-1.png" /></p>
		<p><strong>逐层预训练</strong>：用于分类MNIST的DBM的训练：</p>
		<p>(a)使用CD近似最大化$\log P(v)$来训练RBM。</p>
		<p>(b)训练第二个RBM，使用CD-k近似最大化$\log P(h^{(1)}, y)$来建模$h^{(1)}$和目标类$y$，其中$h^{(1)}$采自第一个RBM条件于数据的后验。</p>
		<p>在学习期间将$k$从$1$增加到$20$。</p>
		<p>(c)将两个RBM组合为DBM。使用$k = 5$的随机最大似然训练，近似最大化$\log P(v, y)$。(d)将$y$从模型中删除。定义新的一组特征$h^{(1)}$和$h^{(2)}$。使用随机梯度下降和Dropout训练MLP近似最大化$\log P(y|v)$。<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/layer-pre.png" /></p>
		<p><strong>联合训练深度玻尔兹曼机</strong>：<img alt="" src="https://raw.githubusercontent.com/applenob/reading_note/master/res/jointly-train.png" /></p>

		<h2 id="实值数据上的玻尔兹曼机：">实值数据上的玻尔兹曼机：<a class="anchor-link" href="#实值数据上的玻尔兹曼机：">¶</a></h2><h3 id="1.Gaussian-Bernoulli-RBM">1.Gaussian-Bernoulli RBM<a class="anchor-link" href="#1.Gaussian-Bernoulli-RBM">¶</a></h3><p>隐藏单元是二元的伯努利分布，可见单元上的条件分布是高斯分布（均值为隐藏单元的函数）。</p>
		<p>条件分布：$p(v∣h)=N(v;Wh,β^{−1})$</p>
		<p>能量函数的一种方式：$E(v,h)=\frac{1}{2}v^⊤(β⊙v)−(v⊙β)^⊤Wh−b^⊤h$。</p>
		<h3 id="2.均值和协方差RBM（Mean-and-Convariance-RBM，mcRBM）">2.均值和协方差RBM（Mean and Convariance RBM，mcRBM）<a class="anchor-link" href="#2.均值和协方差RBM（Mean-and-Convariance-RBM，mcRBM）">¶</a></h3><p>使用隐藏单元独立地编码所有可观察单元的条件均值和协方差。</p>
		<p>mcRBM的隐藏层分为两组单元：均值单元和协方差单元。</p>
		<p>在二值均值的单元h(m)和二值协方差单元h(c)的情况下，mcRBM模型被定义为两个能量函数的组合：</p>
		<p>$E_{mc}(x,h(m),h(c))=E_m(x,h(m))+E_c(x,h(c))$。</p>
		<h3 id="3.学生t分布均值乘积模型（Mean-Product-of-Student's-t-distribution）">3.学生t分布均值乘积模型（Mean-Product of Student's t-distribution）<a class="anchor-link" href="#3.学生t分布均值乘积模型（Mean-Product-of-Student's-t-distribution）">¶</a></h3><p>隐藏变量的互补条件分布是由条件独立的Gamma分布给出。</p>
		<p>能量函数为：</p>
		<p>$E_{mPoT}(x,h(m),h(c))=E_m(x,h^{(m)})+∑_j(h^{(c)}_j(1+\frac{1}{2}(r^{(j)T}x)^2)+(1−γ_j)logh^{(c)}_j)$。</p>
		<h3 id="4.尖峰和平板RBM（Spike-and-Slab-RBM，ssRBM）">4.尖峰和平板RBM（Spike and Slab RBM，ssRBM）<a class="anchor-link" href="#4.尖峰和平板RBM（Spike-and-Slab-RBM，ssRBM）">¶</a></h3><p>尖峰和平板RBM有两类隐藏单元：二值尖峰(spike)单元h和实值平板(slab)单元s。</p>
		<p>条件于隐藏单元的可见单元均值由$(h⊙s)W^⊤$给出。</p>
		<p>换句话说，每一列$W_{:,i}$定义当$h_i=1$时可出现在输入中的分量。</p>
		<p>相应的尖峰变量$h_i$确定该分量是否存在。 如果存在的话，相应的平板变量$s_i$确定该分量的强度。</p>
		<p>当尖峰变量激活时，相应的平板变量将沿着$W_{:,i}$定义的轴的输入增加方差。 这允许我们对输入的协方差建模。</p>
		<h3 id="通过随机操作的反向传播">通过随机操作的反向传播<a class="anchor-link" href="#通过随机操作的反向传播">¶</a></h3><p>传统的神经网络对一些输入变量$x$施加确定性变换；当开发生成模型时，我们经常希望扩展神经网络以实现$x$的随机变换。</p>
		<p>这样做的一个直接方法是使用额外输入$z$来引入随机性。</p>
		<p>函数$f(x,z)$对于不能访问z的观察者来说将是随机的。</p>
		<p>如果f是连续可微的，我们可以像往常一样使用反向传播计算训练所需的梯度：$ω$是同时包含参数$θ$和输入$x$的变量，$y=f(z;ω)$，可以使用传统工具（例如反向传播算法）计算$y$相对于$ω$的导数。</p>
		<p>至关重要的是：$ω$不能是$z$的函数，且$z$不能是$ω$的函数。</p>
		<p>这种技术通常被称为<strong>重参数化技巧（reparametrization trick）、随机反向传播(stochastic back-propagation)或扰动分析(perturbation analysis)</strong>。</p>
		<h3 id="通过离散随机操作的反向传播">通过离散随机操作的反向传播<a class="anchor-link" href="#通过离散随机操作的反向传播">¶</a></h3><p><strong>REINFORCE算法（REward Increment = nonnegative Factor × Offset Reinforcement × Characteristic Eligibility）</strong>提供了定义一系列简单而强大解决方案的框架。</p>
		<p>其核心思想是:即使$J(f(z;ω))$是具有无用导数的阶跃函数，期望代价$E_{z\sim p(z)}J(f(z;ω))$通常是服从梯度下降的光滑函数。</p>
		<p>$E_z[J(y)]=∑_yJ(y)p(y)$，有$\frac{∂E[J(y)]}{∂ω}=∑_yJ(y)\frac{∂p(y)}{∂ω}=∑_yJ(y)p(y)\frac{∂logp(y)}{∂ω}≈\frac{1}{m}∑^m_{y^{(i)}\sim p(y)},i=1$。</p>
		<p>简单REINFORCE估计的一个问题是其具有非常高的方差，需要采y的许多样本才能获得对梯度的良好估计。</p>
		<p>相对于$ω_i$的梯度估计则变为：$(J(y) - b(\omega)_i)\frac{\partial\log p(y)}{\partial \omega_i}$</p>
		<p>b的获取：$b^*(\omega)_i=\frac{E{p(y)} \Big[ J(y) \frac{\partial\log p(y)^2}{\partial \omega_i} \Big]} {E_{p(y)} \Big[\frac{\partial\log p(y)^2}{\partial \omega_i}\Big] }$</p>

		<h2 id="有向生成网络：">有向生成网络：<a class="anchor-link" href="#有向生成网络：">¶</a></h2><h3 id="sigmoid信念网络（Sigmoid-Belief-Nets）">sigmoid信念网络（Sigmoid Belief Nets）<a class="anchor-link" href="#sigmoid信念网络（Sigmoid-Belief-Nets）">¶</a></h3><p>将sigmoid信念网络视为具有二值向量的状态s，其中状态的每个元素都受其祖先影响：
		$p(s_i)=σ(∑_{j< i}W_{j,i}s_j+b_i)$。</p>
		<p>sigmoid信念网络最常见的结构是被分为许多层的结构，其中原始采样通过一系列多个隐藏层进行，然后最终生成可见层。</p>
		<p>这种结构与深度信念网络非常相似，但它们在采样过程开始时的单元彼此独立，而不是从受限玻尔兹曼机采样。</p>
		<h3 id="可微生成器网络（Differentiable-Generator-Nets）">可微生成器网络（Differentiable Generator Nets）<a class="anchor-link" href="#可微生成器网络（Differentiable-Generator-Nets）">¶</a></h3><p>是很多生成模型的基础，使用<strong>可微函数</strong>$g(z;θ(g))$将潜变量z的样本变换为样本$x$或样本$x$上的分布，<strong>可微函数通常可以由神经网络表示</strong>。</p>
		<p><strong>给出x的训练样本，训练可微生成器网络的几种方法</strong>：</p>
		<h3 id="1.变分自编码器（Variational-Autoencoders）">1.变分自编码器（Variational Autoencoders）<a class="anchor-link" href="#1.变分自编码器（Variational-Autoencoders）">¶</a></h3><p>变分自编码器是一个使用学得<strong>近似推断（Learned Approximate Inference）</strong>的有向模型， 可以纯粹地使用<strong>基于梯度</strong>的方法进行训练。</p>
		<p><img alt="" src="http://img.blog.csdn.net/20161214175054421?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvSmFja3lUaW50aW4=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" /></p>
		<p>注：图片来自<a href="http://blog.csdn.net/jackytintin/article/details/53641885">丁丁的博客</a>。</p>
		<p>为了从模型生成样本，VAE首先从编码分布$p_{model}(z)$中采样$z$；</p>
		<p>然后将样本输入到<strong>可微生成器网络</strong> $g(z)$中；最后，从分布$p_{model}(x;g(z)) = p_{model}(x \mid z)$ 中采样$x$。</p>
		<p>在训练期间，近似推断网络（或编码器）$q(z \mid x)$用于获得$z$，而$p_{model}(x \mid z)$则被视为解码器网络。</p>
		<p>$log\;p_{model}(x)\geq L(q)=E_{z\sim q(z|x)}[log\;p_{model}(x|z)]-D_{KL}(q(z|x)||p_{model}(z))$</p>
		<p>变分自编码器方法是优雅的，易于实现的，也获得了不错的结果，是生成式建模中的最先进方法之一。</p>
		<p>它的主要缺点是从在图像上训练的变分自编码器中采样的样本往往有些<strong>模糊</strong>。</p>
		<h3 id="2.生成式对抗网络（Generative-Adversarial-Networks）">2.生成式对抗网络（Generative Adversarial Networks）<a class="anchor-link" href="#2.生成式对抗网络（Generative-Adversarial-Networks）">¶</a></h3><p>生成器网络直接产生样本$x = g(z; theta^{(g)})$。</p>
		<p>判别器网络试图区分从训练数据抽取的样本和从生成器抽取的样本。</p>
		<p>$g^∗=arg\;\underset{g}{min}\;\underset{d}{max}\; v(g,d)$，$v$的默认选择是：$v(θ(g),θ(d))=E_{x\sim p_{data}}logd(x)+E_{x\sim p_{model}}log(1−d(x))$。</p>
		<p>设计GAN的主要动机是学习过程既不需要近似推断也不需要配分函数梯度的近似。</p>
		<p>各种gan的结构：</p>
		<p><img alt="" src="https://pbs.twimg.com/media/CwM0BzjVUAAWTn4.jpg" /></p>

	</div>
</div>
</div>

<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['$','$'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
</div>
<footer>
<br />
<p><a href="https://applenob.github.io">DanteLiujie's blog</a> &copy; DanteLiujie 2018</p>
</footer>

</div> <!-- /container -->
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
<script src="https://applenob.github.io/theme/bootstrap-collapse.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-99008972-1', 'auto');
  ga('send', 'pageview');

</script>
 
</body>
</html>